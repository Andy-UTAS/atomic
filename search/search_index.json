{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-the-home-of-atomic-physics","title":"Welcome to the home of atomic physics","text":"<p>This site exists to enhance the distribution of course information and content for the atomic physics component of KYA323: Atomic and Nuclear Physics. All official communication will be though MyLO<sup>1</sup>.</p> A next-generation trap for strontium ions, recently pulished in the journal nature . Trapped ion systems are promising candidates for quantum computation and quantum sensing, and this system, developed by the MIT Lincoln Laboratory demonstrates an important step in the process of making quantum devices suitable for the real-world, namely, making them \"simpler\" and more robust. As part of this course, we will investigate how atomic physics allows us to understand, model, and construct simple, yet extraordinarily powerful quantum systems. After constructing a foundation in the theory of applied quantum mechanics, we will turn our attention to real-world quantum applications and technology.  <p>Course expectations: my expectations of you</p> <p>Quantum mechanics is tough! And this isn't (necessarily) hyperbole: physics is often put in the \"hard\" basket for a number of reasons, not least due to it being seen as irrelevant or mathematically challenging. Whilst the mathematics can indeed by spicy, once can develop coping mechanisms for this, and at its heart physics is usually intuitive: the apple falls from the tree, like charges repel, and so on. At first glance, quantum mechanics can present very differently, and is rarely accused of being intuitive. There are delights are to be had, but like most truly rewarding endeavours, said delights do not come for free. In undertaking this course, it is expected that:</p> <ul> <li>You will attend all face-to-face sessions, and actively contribute to discussions and problem solving</li> <li>Prescribed problems and reading will be undertaken before any face-to-face sessions</li> <li>If you are experiencing difficulties, that you will get in contact as soon as is reasonably possible</li> </ul> <p>Course objectives</p> <p>The purpose of the atomic component of the atomic and nuclear physics course is to provide a deeper exploration of quantum theory, moving beyond toy examples and developing a toolkit for analysing systems which one would actually encounter in a lab. At the conclusion of your journey, you should:</p> <ul> <li>Be familiar with the fundamentals of atomic physics, notably atomic structure and atomic transitions</li> <li>Understand what makes a quantum system behave in a quantum way, and how one can construct experiments to harness the power of quantum mechanics</li> <li>Have studied diverse quantum applications, from how the GPS network functions, to how to discern different squishy bits in an MRI image, and how to build a quantum computer</li> <li>Have had some fun!</li> </ul> <p>Course expectations: my promises to you</p> <p>Rightly, you should have expectations of me. It is my intention that:</p> <ul> <li>I will work to communicate my understanding and insight in the course material</li> <li>I will actively seek input to steer and shape the content discussed, and develop relevant resources</li> <li>I will be available for consultation and discussion</li> <li>I will do my best to cultivate a safe and open forum for discussion</li> </ul> <p>If you think that I am not fulfilling my commitments, or if you have other comments, I would hope that you are comfortable conveying your concerns and/or comments to me, either directly or anonymously. It is my genuine desire to help you navigate learning new concepts and ideas, and I want to do this to the best of my ability, and feedback is the best way to ensure this endeavour proceeds as smoothly as possible.</p> <ol> <li> <p>For the curious traveller, MyLO is The University of Tasmania's learning management system, based on Brightspace as developed D2L.\u00a0\u21a9</p> </li> </ol>"},{"location":"0-1-intro/","title":"0.1 - Atomic physics 101","text":""},{"location":"0-1-intro/#atomic-physics-101","title":"Atomic physics 101","text":"<p>The fundamental laws necessary for the mathematical treatment of a large part of physics and the whole of chemistry are thus completely known, and the difficulty is only that the exact application of these laws leads to equations much too complicated to be soluble.</p> <p> Paul Dirac </p>"},{"location":"0-1-intro/#introduction","title":"Introduction","text":"<p>A motivating anecdote will soon appear here, and you will be enraptured upon reading as to want to learn more about atomic physics.</p> Futurama meme <p>A somewhat different tone, but both too relevant and too classic to pass up (from S03E14: Time Keeps On Slippin').</p> <p> </p> <p>The study of quantum mechanics is a wild ride: it is punctuated by brief periods of understanding and then profound lulls of nothing making sense. It is often stated that quantum mechanics is counter intuitive, or that it cannot be understood, and whilst there one can argue that a deeper level this is true, one can use the scientific method to probe the universe, and formulate theories which accurately predict what will take place (with extraordinary accuracy!). Repeated exposure to commonly encountered systems and physical situations can be used to cultivate an intuition for might be likely to take place. If you come seeking explanations for quantum phenomena through analogy with \"intuitive\" classical systems, you will leave (mostly) empty handed. The best thing one can do to harness the power of quantum mechanics is take one's time: really marinate in the content. Build on the foundations of your existing physics knowledge (e.g. wave mechanics) and embark on a journey to harness the best model we have for the natural world.</p> <p></p> <p>Image credits</p> <p>Header image taken from physics world.</p>"},{"location":"1-1-early/","title":"1.1 - Early atomic physics","text":""},{"location":"1-1-early/#early-atomic-physics","title":"Early atomic physics","text":"<p>Splitting the atom... Well, splitting atomic emissions into a spectrum</p>"},{"location":"1-1-early/#introduction","title":"Introduction","text":"<p>Our journey begins with what may be the most famous experiment in the context of quantum mechanics, which was undertaken in the early part of the twentieth century. The nascent ideas of quantum mechanics were being explored, and a delightfully simple experiment managed to break our understanding of how the world works. We shall explore the rich physics of this foundational experiment and use it as our foundation for introducing quantum mechanics using Dirac notation and matrix mechanics.</p> <p>Expected competencies</p> <p>It is assumed that you have familiarity with the following concepts/techniques:</p> <ul> <li>Basic spectroscopy</li> <li>Bohr's model of the atom</li> </ul> <p>Text reference</p> <p>The material covered here is discussed in section(s) \\(\\S1.1\\) of Quantum Mechanics, A Paradigms Approach (2nd edition)</p>"},{"location":"1-1-early/#the-year-was-1921","title":"The year was 1921...","text":"<p>A touch over 100 years ago, Otto Stern and Walther Gerlach performed the following experiment:</p> <ul> <li>Creating a beam of neutral silver atoms</li> <li>Passing the beam through an inhomogeneous magnetic field</li> <li>Measuring the beam profile after the magnetic field</li> </ul> <p>A schematic of the experiment is shown below:</p> <p> </p> A schematic of the Stern-Gerlach experiment <p>The experiment is conceptually very simple, and despite the experiment being extremely difficult to execute, they were able to obtain the following result:</p> <p> </p> \"Bohr was right after all\", Walther Gerlach <p>Without context, it is somewhat difficult to appreciate the Earth shattering nature of this image, so that is what we are going to explore.</p>"},{"location":"1-1-early/#the-classical-experiment","title":"The classical experiment","text":"<p>Given there is some interaction between the atoms and the magnetic field, this leads to us assuming that the atom possesses a magnetic moment magnetic moment \\boldsymbol{\\mu}. The energy of the interaction is given by</p> \\[ E = -\\boldsymbol{\\mu} \\cdot \\mathbf{B} \\] <p>where \\(\\mathbf{B}\\) is the magnetic field.</p> Question 1.1.1: What is the force due to this interaction? Write an expression for the force in the \\(z\\)-direction <p>The force is the negative gradient of the energy, which in this case yields</p> \\[ \\mathbf{F} = \\nabla \\left(\\boldsymbol{\\mu} \\cdot \\mathbf{B}\\right) \\] <p>and by the design of the experiment, we know the field is primarily in the \\(z\\)-direction and so</p> \\[ \\begin{align} F_z &amp; = \\frac{\\partial}{\\partial z}\\left(\\boldsymbol{\\mu} \\cdot \\mathbf{B}\\right) \\\\ &amp; \\approx \\mu_z \\frac{\\partial B_z}{\\partial z} \\end{align} \\] <p>Consequently, the force is largely perpendicular to the direction of beam propagation, with the amount of deflection being proportional to the component of the magnetic moment in the direction of the field gradient.</p> <p>The origin of a (classical) magnetic moment is either a separation of poles, or loops of current, and explicitly the magnitude of the magnetic moment \\(\\mu\\) is</p> \\[ \\mu = I \\times A \\] <p>where \\(I\\) is the current in the loop and \\(A\\) is the area of the loop. In the early 1920s, atomic model de jour was the Bohr model<sup>1</sup>, where atoms consist of charges in discrete energy shells, and so we can meaningfully talk about a charge \\(q\\) moving at speed \\(v\\) around the loop of a circle of radius \\(r\\).</p> Question 1.1.2: Show that the magnitude of the magnetic moment is given by \\(qrv/2\\) <p>This is plug and play from \\(\\mu = I \\times A\\), requiring only that one the definition of current:</p> \\[ \\begin{align} \\mu &amp; = I \\times A \\\\ &amp; = \\frac{q}{2\\pi r / v} \\times \\pi r^2 \\\\ &amp; = \\frac{qrv}{2} \\end{align} \\] <p>From rotational mechanics, we know the orbital the angular momentum \\(L = mvr\\), so we rewrite</p> \\[ \\mu = \\frac{q}{2m} L. \\] <p>We also take further inspiration from rotational mechanics in the form of an orbiting body can itself rotate (e.g. the earth spinning whilst rotating around the sun), so we assume our charged particle has</p> <ul> <li>Orbital angular momentum \\(\\mathbf{L}\\)</li> <li>Intrinsic angular momentum \\(\\mathbf{S}\\)</li> </ul> <p>both of which will contribute to the magnetic interaction. By analogy with the orbital angular momentum, we can propose a relation between the magnetic moment and the intrinsic angular momentum as</p> \\[ \\boldsymbol{\\mu} = g\\frac{q}{2m} \\mathbf{S} \\] <p>where \\(g\\) is the dimensionless \\(g-\\)factor which contains all of the juicy physics. Arriving at a theoretical value for this constant goes beyond the scope of this course<sup>2</sup>, but it turns out the value of \\(g\\) is approximately -2, and the deviation from -2 is hailed as one of the grand successes of the theory of Quantum Electrodynamics: the predicted value of</p> \\[ g_{\\mathrm{theory}} = -2.002319304363286 \\] <p>matches the experimental value of</p> \\[ g_{\\mathrm{exp}} = \u00e2\u02c6\u20192.00231930436256(35) \\] <p>very well.</p>"},{"location":"1-1-early/#long-shot-silver","title":"Long-shot silver","text":"<p>We must take a brief sojourn from physics fundamentals to look at the practicalities of the experiment, such that we can realistically model the system.</p> Question 1.1.3: How many common isotopes of silver are there and how many neutrons are in each isotope? How does the existence of these isotopes alter our analysis? <p>The common isotopes of silver are \\(^{107}\\)Ag and \\(^{109}\\)Ag, having 60 and 62 neutrons respectively. Impressively, these isotopes occur with near-similar abundances at \\(51.8%\\) and \\(48.2%\\) respectively.</p> <p>In all cases, the magnetic moment depends on the inverse of the particle mass, so for both protons and neutrons which have a mass some thousands of times bigger, we can simply ignore<sup>3</sup> thier contribution to the magnetic moment of the atom.</p> Question 1.1.4: What is the electronic configuration of Silver? How many unpaired electrons are in the outer shell? What are the consequneces for our (the Stern-Gerlach) experiment? Write an expression of the magnetic moment of neutral silver. <p>The electronic confiuration for silver is</p> \\[ \\mathrm{Ag} = 1\\mathrm{s}^2 2\\mathrm{s}^2 2\\mathrm{p}^6 3\\mathrm{s}^2 3\\mathrm{p}^6 4\\mathrm{s}^2 3\\mathrm{d}^{10} 4\\mathrm{p}^6 4\\mathrm{d}^{10} 5\\mathrm{s}^1 \\] <p>or equivalently</p> \\[ \\mathrm{Ag} = [\\mathrm{Kr}] 4\\mathrm{d}^{10} 5\\mathrm{s}^1 \\] <p>meaning that there is only a single unpaired electron in the outer shell, and it is also in the ground state, which has an isotropic distribution and thus no orbital angular momentum, meaning only the intrinsic angular momentum of the electron will contribute to the interaction.</p> <p>The magnetic moment for the silver atom is then</p> \\[ \\boldsymbol{\\mu} = -g\\frac{e}{2 m_e} \\mathbf{S} \\] <p>where \\(e\\) is the magnitude of the electron charge and \\(m_e\\) is the electronic mass.</p> <p>Are we baking in the result for the classical analysis by using what amounts to quantum info?</p> <p>Yes, but this needn't be the case; however, it really simplifies the discussion. The Stern-Gerlach experiment was done with neutral silver, so we seek to analyse this result; but we could look at the case of Hydrogen (which was done afterwards) or the plethora of other systems, but multielectron systems do require a bit of modern knowledge to make the classical analysis fit together. An interesting thought is why don't we do the experiment or analysis with electrons themselves?</p> <p>The force in the the \\(z-\\) direction for a silver atom is thus</p> \\[ \\begin{align} F_z &amp; \\approx \\mu_z \\frac{\\partial B_z}{\\partial z} \\\\ &amp; = - g \\frac{e}{2 m_e} S_z \\frac{\\partial B_z}{\\partial z} \\end{align} \\] <p>and directly, we have the deflection of the beam through the apparatus being a direct measurement of the \\(z\\) component of the spin along the axis of the magnetic field gradient.</p> Question 1.1.5: Make a prediction of the distribution of deflected silver atoms you would expect for a thermal source. <p>A reasonable assumption one can make is that the intrinsic angular momentum for each \\(5\\mathrm{s}\\) electron has the same magnitude, and thus we can write the \\(z-\\)component as</p> \\[ S_z = |\\mathbf{S}|\\cos\\left(\\theta\\right) \\] <p>where \\(\\theta\\) is the angle between the \\(z-\\)axis and the spin vector \\(\\mathbf{S}\\). For a thermal beam, we would expect all values of \\(\\theta\\), with the explicit angular flux to be determined by the apparatus; however, the from of this being largely unimportant save for the fact we expect all values of \\(\\theta\\) to be present. We therefore would expect a continuous range of spin projections, ranging from \\(S_z \\in [-|\\mathbf{S}|, |\\mathbf{S}|]\\)</p>"},{"location":"1-1-early/#the-results","title":"The results","text":"Reprint: the experimental results of the original Stern-Gerlach experiment <p>We can now return to the results as recorded by Stern and Gerlach. If we look at the image without the magnetic field gradient, we see the silver beam form a line (which is due to the geometry of experiment) and when the gradient is switched on, only two projections along the field gradient are observed, which indicates only two values of the \\(z-\\) component of the electron spin are possible. The magnitude of these deflections are consistent with the values of the spin component of</p> \\[ S_z = \\pm \\frac{\\hbar}{2} \\] <p>where the reduced Planck constant is \\(\\hbar = h/2\\pi\\) and Plank's constant is \\(h=6.62607015 \\times 10^{-34}~\\mathrm{J \\cdot Hz^{-1}}\\). The Stern-Gerlach experiment is evidence of the quantisation of the electron spin angular momentum along an axis.</p> <p>The quantisation axis</p> <p>In our working here, we have chosen the \\(z-\\)axis to be the direction along which we measure the spin component, but we could have equally picked any other axis and observed the same result. It is a well-observed convention to define the axis of the magnetic field (gradient) to be along \\(z\\), and we are not going to start rocking the boat.</p>"},{"location":"1-1-early/#a-general-stern-gerlach-experiment","title":"A general Stern-Gerlach experiment","text":"<p>We are going to regroup: with your socks (hopefully) having been blown off by the above result, we are going to move into a generalised framework to consider these kinds of experiments - and yes, should you need to take a minute to collect you socks, please do so now.</p>"},{"location":"1-1-early/#details-in-the-bin","title":"Details in the bin","text":"<p>We are going to strip back the Stern-Gerlach experiment to the core features, which consists of the following:</p> <ul> <li>A beam of atoms</li> <li>A Stern-Gerlach device which analyses the component of spin along a given axis</li> </ul> <p>A schematic of the system is shown below:</p> <p> </p> A schematic of the simplified Stern-Gerlach system <p>We are also going to label the output ports of our analyser: the up and down arrows (\\(\\uparrow\\) and \\(\\downarrow\\)) indicate the possible measurement results for the analyser, which correspond to the measurements</p> \\[ S_z = \\pm \\frac{\\hbar}{2} \\] <p>and as there are only two results, we can refer to these as spin up and spin down. The thing that we are measuring, the projection of \\(\\mathbf{S}\\) onto the \\(z-\\)axis (\\(S_z\\)) is the observable, i.e. the thing we are measuring.</p>"},{"location":"1-1-early/#the-quantum-state","title":"The quantum state","text":"<p>When we talk about the beams in our system, be it the input beam or the beams after the analyser, we are describing quantum states. In the first part of this course, you will have encountered quantum mechanical states in the context of wavefunctions, which are solutions to the Schr\u00c3\u00b6dinger equation. Here we adopt a more general representation of quantum states, which is not limited to the degrees of freedom chosen to represent the wavefunction (e.g. position/momentum space) but rather talk about a state as an object containing all of the information that we can know about the system. Mathematically, we represent states using  Dirac notation; in the case of our spin up and spin down states, we label these \\(|+\\rangle\\) and \\(|-\\rangle\\), where we have introduced a new symbol to demarcate a quantum state, the ket. We will delve deeper into these objects later, but for the moment it sufficient to know that a general state is mathematically described by the ket \\(|\\psi\\rangle\\).</p> <p>Uniqueness of ket labels</p> <p>A quantum state is described by a ket, but the label in the ket is not unique. For example, we might label the spin-up state as</p> <ul> <li>\\(| + \\rangle\\)</li> <li>\\(| S_z = +\\hbar/2 \\rangle\\)</li> <li>\\(| +\\mathbf{\\hat{z}} \\rangle\\)</li> <li>\\(| \\uparrow \\rangle\\)</li> <li>\\(\\ldots\\)</li> </ul> <p>where the label is not important; in all cases, we are talking about the state with a projection of \\(+\\hbar/2\\) through our Stern-Gerlach analyser.</p> <p>Postulate 1</p> <p>The state of a quantum mechanical system - the entirety of information that you can know about it - is represented mathematically by a normalised ket \\(|\\psi\\rangle\\)</p> <p>We now seek to perform a series of experiments which the systems will behave exactly as expected and no strange behaviour will take place.</p> <p>Experiment simulator</p> <p>An online simulation is available to allow you to play along with the following experiments.  </p>"},{"location":"1-1-early/#experiment-one","title":"Experiment one","text":"<p>The following set of experiments are conducted by sending our beam through various analysers. An example of such an experiment from our simple setup above is shown below:</p> <p> </p> The simplified Stern-Gerlach experiment with proportions of atoms detected from the output ports <p>In our first example, we are going to stack two analysers aligned along the \\(z-\\)axis. The beam will be split by the first analyser, and we then take the spin up component of the beam and use this as the input to a second analyser, meaning the spin component is again analysed.</p> <p>Experiment time</p> Experimental setupExperimental results <p> What will the proportion of particles detected at the output ports? </p> <p> </p> <p>This result is perhaps unsurprising, as the first analyser measures an atom to have a \\(z-\\)component of spin \\(S_z = +\\hbar/2\\), and the 2nd analyser also measures \\(S_z = +\\hbar/2\\) for these atoms. It should be emphasised that in this scenario, the first analyser can be considered to be preparing the quantum state: if we have a mixture of spin up and spin down atoms before the analyser, atoms from a given output port will be either spin up or spin down.</p>"},{"location":"1-1-early/#experiment-two","title":"Experiment two","text":"<p>We are now going to preform the same experiment as experiment one with the exception being that we are going to replace the second analyser with an analyser which is aligned to the \\(x-\\)axis, meaning that we now measure the \\(x\\) component of the spin \\(S_x\\) rather than \\(S_z\\).</p> <p>Experiment time</p> Experimental setupExperimental results <p> What will the proportion of particles detected at the output ports? </p> <p> </p> <p>At the top port of the first analyser, we still have atoms in the spin up state \\(|+\\rangle\\) as per the previous example, but following the second analyser, we have atoms which have components \\(S_x = +\\hbar/2\\) and \\(S_x = -\\hbar/2\\), which we denote by \\(|+\\rangle_x\\) and \\(|-\\rangle_x\\) respectively. Points of note from this experiment are</p> <ul> <li>Even though we have changed the orientation of the analyser, there are still only two possible values for the projection of the spin</li> <li>Results for this experiment would be unchanged if we had taken the spin down output from the first analyser</li> <li>Critically: for any given atom, we cannot predict the output of the second analyser. We know that there will be a \\(50\\%\\) probability of an atom exiting via a specific port, but nothing more</li> </ul> <p>Quantum mechanics is inherently probabilistic: we cannot know the outcome of a given measurement without making said measurement. In the development of quantum mechanics, it was postulated that whilst measurements appeared to be probabilistic, there was actually some other variable which was underwriting the system, which if known would allow us to conclusively predict results. This so-called hidden variable theory of quantum mechanics was shown to be incompatible with observed results<sup>4</sup>, something we shall discuss in detail later in the course.</p>"},{"location":"1-1-early/#experiment-three","title":"Experiment three","text":"<p>We shall now extend experiment two with the addition of a third analyser, again aligned along the \\(z-\\)axis, meaning we are measuring the component of the spin along the \\(z\\), \\(x\\), and \\(z\\) axes respectively.</p> <p>Experiment time</p> Experimental setupExperimental results <p> What will the proportion of particles detected at the output ports? </p> <p> </p> <p></p> <p>If this result does not cause a double take, then marinate in it a bit longer until that happens. We have measured \\(S_z = +\\hbar/2\\), then we have taken a measurement of \\(S_x\\), and then immediately taken another measurement of \\(S_z\\), but the result is now a mixture of \\(S_z = +\\hbar/2\\) and \\(S_z = -\\hbar/2\\). Somehow, by measuring \\(S_x\\), we have erased knowledge of \\(S_z\\).</p> <p>A key feature of quantum mechanics is that making a measurement fundamentally alters the system. These experiments are designed to illustrate that there is a fundamental incompatibility between measurements of different spin components, or formally: that \\(S_x\\) and \\(S_z\\) are incompatible observables. This means that we cannot these values simultaneously.</p> <p>Compatible versus incompatible observables</p> <p>In this case we see that \\(S_z\\) is incompatible with \\(S_x\\) (and also \\(S_y\\)), but this does not mean that all pairs of observables are incompatible. It is an important aspect of quantum mechanics that we can make certain measurements without altering other aspects of the system. We shall discuss this in detail later, but for now it is sufficient to say that there are both sets of compatible observables and incompatible observables.</p>"},{"location":"1-1-early/#experiment-four","title":"Experiment four","text":"<p>For our final experiment, we are going to repeat experiment three but we are going to alter the beam as it comes out of analyser number 2: namely change what goes into analyser number three.</p> <p>Experiment time</p> Experimental setupSpin up onlySpin down onlyCombined spin up and spin down <p> What will the proportion of particles detected at the output ports? </p> <p> </p> <p>This is exactly the same as experiment three.</p> <p> </p> <p>This is in effect, exactly the same as experiment three.</p> <p> </p> <p></p> <p>This result is perhaps the strangest of all: by recombining the outputs from the second analyser, we have somehow made the atoms recall their state from the output of analyser number one! Classical probability theory cannot explain this aspect of quantum mechanics.</p> <p>Whilst these results may appear extremely foreign, you already have an intuition for what is going on: consider the canonical double-slit experiment. When light waves pass through slits, each slit produces a nearly uniform illumination of the screen, but when the two slits are allowed to combine, an interference pattern in observed. In order to describe this phenomenon, we consider the complex-valued electric fields from both sources, and ultimately calculate the intensity as the square of the field amplitude, and the nature of complex-valued fields permits interference effects. In this sense, quantum mechanical is no different to any other form of wave mechanics, but we must work to describe and calculate the amplitudes of the quantum mechanical waves.</p>"},{"location":"1-1-early/#conclusions","title":"Conclusions","text":"<p>The Stern-Gerlach experiment demonstrates some foundational concepts of quantum mechanics:</p> <ol> <li>Quantum mechanics is probabilistic</li> <li>Spin measurements are quantised</li> <li>Quantum measurements disturb the system</li> </ol>"},{"location":"1-1-early/#exercises","title":"Exercises","text":""},{"location":"1-1-early/#preliminary-provocations","title":"Preliminary provocations","text":"<ol> <li>Why use an inhomogeneous magnetic field?</li> <li>Why is the experiment done with silver atoms?</li> </ol>"},{"location":"1-1-early/#heavy-hitters","title":"Heavy hitters","text":"<p>1. 2.</p> <p>Image credits</p> <p>Header image taken from the PhD thesis Spinor Bose-Einstein condensates in magnetic field gradients</p> <ol> <li> <p>more accurately, at this time it was the Bohr-Sommerfeld model, which is an extension of the Bohr model to include elliptical orbits which fixed some problems. One will also see in solid-state physics that Sommerfeld has a real talent for tweaking existing theories to make them run a bit better.\u00a0\u21a9</p> </li> <li> <p>A study of the the relativistic wave equation, known as the Dirac equation, is required to fully flesh out this result.\u00a0\u21a9</p> </li> <li> <p>In this case we can, but more generally, the magnetic moment of the nucleus cannot be ignored (see LINK ME! hyperfine splitting)\u00a0\u21a9</p> </li> <li> <p>The 2022 Nobel Prize in physics was awarded for the pioneering work of making these measurements\u00a0\u21a9</p> </li> </ol>"},{"location":"1-2-hydrogen/","title":"1.2 - The hydrogen atom","text":""},{"location":"1-2-hydrogen/#the-hydrogen-atom","title":"The hydrogen atom","text":"<p>The \"simplest\" system</p>"},{"location":"1-2-hydrogen/#introduction","title":"Introduction","text":"<code>Lorem ipsum dolor sit amet</code> <p>Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis.</p>"},{"location":"1-2-hydrogen/#conclusions","title":"Conclusions","text":""},{"location":"1-2-hydrogen/#exercises","title":"Exercises","text":""},{"location":"1-2-hydrogen/#preliminary-provocations","title":"Preliminary provocations","text":"<ol> <li>"},{"location":"1-2-hydrogen/#heavy-hitters","title":"Heavy hitters","text":"<ol> <li> Find the expectation values for  for \\(k=-3,-2,-1, 1, 2\\)</li> </ol> <p>Image credits</p> <p>Header image taken from the paper Hydrogen Atoms under Magnification: Direct Observation of the Nodal Structure of Stark States</p> <ol> <li> <p>more accurately, at this time it was the Bohr-Sommerfeld model, which is an extension of the Bohr model to include elliptical orbits which fixed some problems. One will also see in solid-state physics that Sommerfeld has a real talent for tweaking existing theories to make them run a bit better.\u00a0\u21a9</p> </li> <li> <p>A study of the the relativistic wave equation, known as the Dirac equation, is required to fully flesh out this result.\u00a0\u21a9</p> </li> <li> <p>In this case we can, but more generally, the magnetic moment of the nucleus cannot be ignored (see LINK ME! hyperfine splitting)\u00a0\u21a9</p> </li> </ol>"},{"location":"1-3-methods/","title":"1.3 - Calculation methods for real systems","text":""},{"location":"1-3-methods/#state-vectors","title":"State vectors","text":"<p>Time to do the same experiment lots of times and get different results</p>"},{"location":"1-3-methods/#introduction","title":"Introduction","text":"<code>Lorem ipsum dolor sit amet</code> <p>Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis.</p>"},{"location":"1-3-methods/#conclusions","title":"Conclusions","text":""},{"location":"1-3-methods/#exercises","title":"Exercises","text":""},{"location":"1-3-methods/#preliminary-provocations","title":"Preliminary provocations","text":"<ol> <li>What happens if you happen to choose your variational wavefunction perfectly? That is, you trail wavefunction is an eigenstate of the Hamiltonian?</li> </ol> <p>  as you might expect</p>"},{"location":"1-3-methods/#heavy-hitters","title":"Heavy hitters","text":"<p>Image credits</p> <p>Header image taken from the PhD thesis Spinor Bose-Einstein condensates in magnetic field gradients</p> <ol> <li> <p>more accurately, at this time it was the Bohr-Sommerfeld model, which is an extension of the Bohr model to include elliptical orbits which fixed some problems. One will also see in solid-state physics that Sommerfeld has a real talent for tweaking existing theories to make them run a bit better.\u00a0\u21a9</p> </li> <li> <p>A study of the the relativistic wave equation, known as the Dirac equation, is required to fully flesh out this result.\u00a0\u21a9</p> </li> <li> <p>In this case we can, but more generally, the magnetic moment of the nucleus cannot be ignored (see LINK ME! hyperfine splitting)\u00a0\u21a9</p> </li> </ol>"},{"location":"2-1-hyperfine/","title":"2 1 hyperfine","text":"<pre>\n\nfrom matplotlib import pyplot\nimport numpy as np\n\nfrom common import draw_classic_axes, configure_plotting\n\nconfigure_plotting()\n\n  </pre>"},{"location":"2-1-hyperfine/#state-vectors","title":"State vectors","text":"<p>Time to do the same experiment lots of times and get different results</p>"},{"location":"2-1-hyperfine/#introduction","title":"Introduction","text":"<pre># Data from Einstein's paper\nT = [222.4, 262.4, 283.7, 306.4, 331.3, 358.5, 413.0, 479.2, 520.0, 879.7, 1079.7, 1258.0]\nc = [0.384, 0.578, 0.683, 0.798, 0.928, 1.069, 1.343, 1.656, 1.833, 2.671, 2.720, 2.781]\n\nfig, ax = pyplot.subplots()\nax.scatter(T, c)\nax.set_xlabel('$T [K]$')\nax.set_ylabel('$C/k_B$')\nax.set_ylim((0, 3))\nax.set_title('Heat capacity of diamond')\nfig.show()</pre>"},{"location":"2-1-hyperfine/#conclusions","title":"Conclusions","text":""},{"location":"2-1-hyperfine/#exercises","title":"Exercises","text":""},{"location":"2-1-hyperfine/#preliminary-provocations","title":"Preliminary provocations","text":"<ol> <li>What happens if you happen to choose your variational wavefunction perfectly? That is, you trail wavefunction is an eigenstate of the Hamiltonian?</li> </ol> <p>  as you might expect</p>"},{"location":"2-1-hyperfine/#heavy-hitters","title":"Heavy hitters","text":"<p>Image credits</p> <p>Header image taken from the PhD thesis Spinor Bose-Einstein condensates in magnetic field gradients</p> <ol> <li> <p>more accurately, at this time it was the Bohr-Sommerfeld model, which is an extension of the Bohr model to include elliptical orbits which fixed some problems. One will also see in solid-state physics that Sommerfeld has a real talent for tweaking existing theories to make them run a bit better.\u00a0\u21a9</p> </li> <li> <p>A study of the the relativistic wave equation, known as the Dirac equation, is required to fully flesh out this result.\u00a0\u21a9</p> </li> <li> <p>In this case we can, but more generally, the magnetic moment of the nucleus cannot be ignored (see LINK ME! hyperfine splitting)\u00a0\u21a9</p> </li> </ol>"},{"location":"6-2-molecules/","title":"State vectors","text":""},{"location":"6-2-molecules/#state-vectors","title":"State vectors","text":"<p>Time to do the same experiment lots of times and get different results</p>"},{"location":"6-2-molecules/#introduction","title":"Introduction","text":"<code>Lorem ipsum dolor sit amet</code> <p>Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis.</p> <p>Given this, along with</p> \\[ \\cos \\theta Y_{l m}(\\theta, \\phi)=\\left(\\frac{l^2-m^2}{4 l^2-1}\\right)^{1 / 2} Y_{l-1, m}(\\theta, \\phi)+\\left[\\frac{(l+1)^2-m^2}{4(l+1)^2-1}\\right]^{1 / 2} Y_{l+1, m}(\\theta, \\phi), \\] <p>and</p> \\[ \\int d \\Omega Y_{l^{\\prime} m^{\\prime}}^*(\\theta, \\phi) Y_{l m}(\\theta, \\phi)=\\delta_{l^{\\prime} l} \\delta_{m^{\\prime} m} \\] <p>gives us</p> \\[ \\left\\langle l^{\\prime}, m^{\\prime}|\\cos \\theta| l, m\\right\\rangle=\\delta_{m^{\\prime} m}\\left\\{\\left(\\frac{l^2-m^2}{4 l^2-1}\\right)^{1 / 2} \\delta_{l^{\\prime}, l-1}+\\left[\\frac{(l+1)^2-m^2}{4(l+1)^2-1}\\right]^{1 / 2} \\delta_{l^{\\prime}, l+1}\\right\\} . \\]"},{"location":"6-2-molecules/#conclusions","title":"Conclusions","text":""},{"location":"6-2-molecules/#exercises","title":"Exercises","text":""},{"location":"6-2-molecules/#preliminary-provocations","title":"Preliminary provocations","text":"<ol> <li>What happens if you happen to choose your variational wavefunction perfectly? That is, you trail wavefunction is an eigenstate of the Hamiltonian?</li> </ol> <p>  as you might expect</p>"},{"location":"6-2-molecules/#heavy-hitters","title":"Heavy hitters","text":"<p>Image credits</p> <p>Header image taken from the PhD thesis Spinor Bose-Einstein condensates in magnetic field gradients</p> <ol> <li> <p>more accurately, at this time it was the Bohr-Sommerfeld model, which is an extension of the Bohr model to include elliptical orbits which fixed some problems. One will also see in solid-state physics that Sommerfeld has a real talent for tweaking existing theories to make them run a bit better.\u00a0\u21a9</p> </li> <li> <p>A study of the the relativistic wave equation, known as the Dirac equation, is required to fully flesh out this result.\u00a0\u21a9</p> </li> <li> <p>In this case we can, but more generally, the magnetic moment of the nucleus cannot be ignored (see LINK ME! hyperfine splitting)\u00a0\u21a9</p> </li> </ol>"},{"location":"additional/","title":"Additional resources","text":""},{"location":"additional/#additional-resources","title":"Additional resources","text":"<p>This page is the space for additional resources which may prove to be of some use and/or interest for curious individuals.</p> <p>Websites</p> <ul> <li>Besides being a best-in-class mathematics educator, Grant Sanderson, a.k.a. 3Blue1Brown, has an excellent video series on the essence of linear algebra, which works to give you firm geometric grounding and build intuition in an area which is often taught in a highly abstract way, far removed from its practical application and implications. Given the heavy lifting that is done by linear algebra in atomic physics - and physics more generally - a quick brush-up on the subject, which is taught in such an insightful and refreshing manner, is well worth your time.</li> </ul> <p>Texts</p> <ul> <li>Undergraduate texts for quantum mechanics are common; however, concise, informed, relevant, and entertaining texts are much less common. I think the texts prescribed for both quantum and atomic physics are the best texts for the courses, but other texts which are recommended include<ul> <li>The classic - and increasingly difficult to find - Physics of Atoms and Molecules by B H Bransden and Charles J. Joachain</li> <li>A Modern Approach to Quantum Mechanics, Second Edition by John S. Townsend from Harvey Mudd College</li> <li>Introduction to Quantum Mechanics by David J. Griffiths and Darrell F. Schroeter from Reed College</li> <li>Quantum Mechanics by Daniel A. Steck from the University of Oregon</li> <li>Harry Potter and the methods of rationality by Eliezer Eudkowsky. Who know that Harry Potter fan fiction could provide such insight. As a jumping off point: Petunia married a biochemist, and Harry grew up reading science and science fiction. Then came the Hogwarts letter, and a world of intriguing new possibilities to exploit.</li> </ul> </li> </ul> <p>Previous course notes</p> <p>Atomic physics at UTAS is taught every second (even-numbered) year, with the previous course outing having been taught by Krzysztof Bolejko and Ross Turner for atomic physics and nuclear physics respectively. The notes from the 2022 course are posted here as a reference, but it should be emphasised that the course structure is vastly different, and consequently one's mileage may vary.</p> <p>Atomic physics</p>"},{"location":"maths/","title":"Mathematical marvels","text":""},{"location":"maths/#mathematical-marvels","title":"Mathematical marvels","text":"<p> Physical constants and mathematical formulae</p> <p> Clebsch-Gordan coefficients</p>"},{"location":"maths/#diagonalization-of-a-3-times-3-matrix","title":"Diagonalization of a \\(3 \\times 3\\) Matrix","text":"<p>Given a matrix \\(A\\):</p> \\[ A = \\begin{pmatrix} a_{11} &amp; a_{12} &amp; a_{13} \\\\ a_{21} &amp; a_{22} &amp; a_{23} \\\\ a_{31} &amp; a_{32} &amp; a_{33} \\end{pmatrix} \\] <ol> <li>Find the eigenvalues by solving the characteristic equation:  </li> <li>Find the eigenvectors for each eigenvalue \\(\\lambda\\) by solving:  </li> <li>Form the matrix \\(P\\) using the eigenvectors as columns:  </li> <li>Construct the diagonal matrix \\(D\\) with the eigenvalues on the diagonal:  </li> <li>\\textbf{Verify} that \\(A = PDP^{-1}\\).</li> </ol>"},{"location":"particulars/","title":"Course particulars","text":""},{"location":"particulars/#course-information","title":"Course information","text":""},{"location":"particulars/#administration","title":"Administration","text":"<p>The atomic physics component of the atomic and nuclear physics course will run for six weeks, beginning in week one and concluding at the end of week six. In previous years, atomic physics acted to reenforce the content discussed in the advanced wave mechanics and quantum mechanics course, spending time on trying to understand atomic structure in a piecewise manner. In contrast, this course begins where the quantum mechanics course left off: the conclusion for most introductory quantum courses is the full solution to the Schr\u00c3\u00b6dinger equation for the hydrogen atom, and poking at the structure of helium. We take these foundations, and construct a framework for understanding and predicting the structure of more complex systems, and importantly, the kind of systems would encounter in wild. Moreover, we will explicitly discuss how one designs and executes experiments in a real-world context with the aim to cultivate an appreciation for quantum systems actually being accessible, and not just problems which appear on whiteboards.</p> <p>Prerequisite knowledge</p> <p>The content covered in atomic physics is testing, and without the firm bedrock of requisite knowledge and associated competencies, attempts to construct additional structures may be compromised. It is critical that one is comfortable with the following:</p> <ul> <li>The principles and machinery of wave mechanics. Explicitly, an understanding of how physical systems and their evolution are modelled using the wave equation, along with a fluency in common examples (plane-wave solutions, travelling waves, etc.).</li> <li>The foundations of quantum mechanics, including the (time dependent) Schr\\(\\\"{o}\\)dinger equation and its solutions for common physical systems, and importantly, you must be comfortable with the physical concepts which underpin the mathematics. Fortunately, you have just completed an introductory quantum mechanics course, and it will be assumed that you are comfortable with the content.</li> </ul> <p>It is my intention that you will be required to call upon many of the other tools from the toolbox that you have been developing during your studies, with the explicit aim of further honing these tools, and maybe adding a few to the kit.</p> <p>This looks familiar</p> <p>If you are experiencing a sense of d\u00e9j\u00e0 vu, that might be because you have encountered one of the other websites which are part of the quantum family of sites:</p> <ul> <li>Quantum mechanics</li> <li>Solid-state physics</li> </ul> <p>In particular, much of the content from the quantum site is directly relevant to this course, and it could well be considered a sister site.</p>"},{"location":"particulars/#delivery-of-content","title":"Delivery of content","text":"<p>The course will be run in a traditional.</p>"},{"location":"particulars/#subject-matter","title":"Subject matter","text":"<p>The content for this course draws heavily from a set of reference texts:</p> <ol> <li>The excellent text Quantum Mechanics, A Paradigms Approach (2nd edition) by David H. McIntyre</li> <li>The go-to reference for basic atomic physics, aptly named Atomic Physics by Christopher J. Foot</li> <li>The intensely thorough Quantum and Atom Optics by Daniel A. Steck</li> </ol> <p>With Foot being the prescribed text for the course, that is, it is assumed that you will have access to this book. This was chosen as McIntyre is the prescribed text for Quantum mechanics, and the two are somewhat complimentary. Steck is a glorious reference - and freely available - but our atomic physics journey only scratches the surface of the material covered in these notes, and as such it is not appropriate as a prescribed text. With this trilogy of titles, you will be well placed to understand why atoms are the way they are, and how to make them do what you want them to do. It is also one of the best introductory texts on the subject, so whether you fall deeply into the quantum rabbit hole or pack it all in to cultivate vanilla in Madagascar, your will be able to polish up on the basics thanks to the text.  </p> <p>Wait, are you actually prescribing textbooks?</p> <p>Yes. And no, you haven't just been transported to 1993; I endeavour to employ evidence-based, best-practice methods for teaching, and this includes deploying many modern teaching aids, and also includes ensuring a glorious reference is prescribed. I will be working from hardcopies, and I encourage you to do the same, although softcopies can be a more cost-effective option.</p>"},{"location":"particulars/#course-outline","title":"Course outline","text":"<p>Make yourself at home for our journey into atomic and nuclear physics. In this course we are going to study fundamental physical systems, which, on their surface can often appear simple, but are delightfully rich, engaging, and powerful. A testament to the foundational nature, utility, and continuing importance of the topics covered in this course is that during the period between 1995 - 2017, the fields of atomic and particle physics accounted for 25% of all Nobel prizes in science that were awarded. It is with this backdrop that we shall set out and seek to understand the fundamental properties and interactions of atoms and nuclei.</p> <p>Course summary</p> <p>This subject is designed to be a meaningful introduction to atomic physics. Hopefully your foray into the world of quantum mechanics was enjoyable, but it is almost inevidable that it left you with more questions than answers. Notably, most introductory quantum mechancis courses finish at the same spot: with the full-blown calculation of the energy eigenstates of the Hamiltonian for the hydrogen atom (in the nonrelativistic case). Whilst such a calculation is a triumph in its own right, the first question that you may ask is: \"does the hydrogen emission spectrum match my prediction\". The answer is no, and there are many distinct ways in which it does not match, due to different phenomena which arise from considering the atom in more detail. It is not the intention of this course the completely describe the hydrogen atom, on the contrary, we want to be able to describe all the atoms! This will mean developing theories and methods of calculation for multielectron systems, ensembles of atoms, and even touching on what happens with multiple nuclei. If your quantum mechanics course was a taster for what is out there in the quantum world; atomic physics narrows the focus of quantum mechanics to the measurement, manipulation, and evolution of atoms and their internal electronic transitions, our understanding of which provides our best tests of how the universe works, along with tests of how well we can predict how the universe works. The building blocks we shall study are basic atomic physics, angular momentum coupling, systems of indistinguishable particles, enesmbles of atoms, modern applications of atomic physics and molecular physics. It is worth noting that I am an experimental physicist by training, and it is my duty to ensure that experimental details permiate all that we study, because at the end of the day, we do need to actually make measurements to test our scientific theories: without this, one lives in a world of fiction.</p> <p>A rough outline of the course is as follows:</p> <ol> <li>Early atomic physics, the hydrogen atom, computational methods</li> <li>Hyperfine structure, angular momentum coupling</li> <li>Identical particles, transitions</li> <li>The density matrix</li> <li>Applications</li> <li>Molecular physics</li> </ol> <p>with approximately one week devoted to each topic, but with the natural ebb and flow ultimately dictating the timeline.</p>"},{"location":"particulars/#the-notes","title":"The notes","text":"<p>The notes on this site are designed to be consumed in concert the content from class, with certain aspects highlighted differently in the different media; in extreme cases, different paths are used to arrive at the same destination. One of my aims is to expose you to different ways of thinking about problems, not just have the same method and then just \"press play\".</p> <p>Expected competencies</p> <p>Content has been constructed with the assumption that the material is consumed sequentially, with sections often explicitly relying on results from previous work. I have also to placed expected competency markers at the beginning of each section, outlining knowledge that I expect you to have seen in other areas of study, and importantly, these are cumulative from section to section.</p> <p>Text reference</p> <p>You will also encounter text references at the beginning of each section, relating to the relevant content in the course texts</p> <p>Computational content</p> <p>Computational content, which is normally just the jupyter notebook associated with the section, also appears at the top of the page, but may also contain links to other software or pertinent computational material.</p>"},{"location":"particulars/#slides","title":"Slides","text":"<p>In the first iteration of this class, content will be deliverd with a mixture of curated presentation material and whiteboarding. Below you can find slides for the in-class presentations, but note that content is delibrately missing from these collections - usually many whole slides or sections - and this content will be covered in class.</p> <ul> <li> <p> Week 1</p> <p>Introductory atomic physics, the hydrogen atom, and computational methods for real systems</p> <p> Week 1</p> </li> <li> <p> Week 2</p> <p>Hyperfine structure, angular momentum, and the coupling of angular momentum</p> <p> Week 2</p> </li> <li> <p> Week 3</p> <p>Identical particles, multielectron atoms, and atomic transitions</p> <p> Week 3</p> </li> <li> <p> Week 4</p> <p>The density matrix, the optical bloch equations, Rabi oscillations</p> <p> Week 4</p> </li> <li> <p> Week 5</p> <p>Atomic timekeeping, quantum sensing, mechanical effects of quantum interactions</p> <p> Week 5</p> </li> <li> <p> Week 6</p> <p>Molecular physics, quantum chemistry</p> <p> Week 6</p> </li> </ul>"},{"location":"particulars/#support","title":"Support","text":"You are not on this journey alone: there are many avenues available to you to help you on the journey (depending on your inclination to watch fantasy movies in the 2000s, you may or not take comfort in the support Harry Potter received by those around him). <p>The course materials as consumed through the content download components are necessarily an individual effort, but in all other facets I strongly encourage collaboration. The structure of content unpacking sessions is deliberately geared towards discussion, the exchange of ideas, and collective problem solving moreso than the execution of a solution finding program.  </p> <p>Quote</p> <p>... there's something in science like the shine of the Patronus Charm, driving back all sorts of darkness and madness ...</p> <p></p><p> Eliezer Eudkowsky (Less Wrong), Harry Potter and the methods of rationality</p>"},{"location":"particulars/#computational-resources","title":"Computational resources","text":"<p>As part of the course, it will be expected that you perform calculation and computations. You are welcome to do this in which ever language you prefer, but it is strongly recommended that you use <code>Python</code>, and indeed, this is the only language that will be supported. In order to ensure equitable and easy access to Python computing resources, a Jupyter Notebook server has been established, which allows for one to write and execute code via a web browser. The server is named Jove<sup>1</sup>, and access is through the JupyterHub portal. You will need to create an account to start using the server, but beyond this is should be click and go. Should you experience any problems getting this up and running, please see the computation section of POLUS.</p> <p>Should you have a machine upon which you already have, or you wish to deploy, your own instance of <code>Python</code>, this is perfectly acceptable, but note that you will have to manually import the distributed materials into Jupyter. This can be effectively accomplished using the clone functionality of GitHub as this is where the course content is hosted.</p>"},{"location":"particulars/#bug-catcher","title":"Bug catcher","text":"<p> Finally, this is more of a request than anything else, but should you find any errors in the content - this site, the distributed notebooks, whatever - please let me know so I can correct the content, which is a major boon for everyone involved. Thanks!</p> <ol> <li> <p>For those wondering, Jove is an alternate name for the Roman god Jupiter.\u00a0\u21a9</p> </li> </ol>"},{"location":"s-a-1/","title":"Assignment 1","text":"<pre>\n\nfrom matplotlib import pyplot\nimport numpy as np\n\nfrom common import draw_classic_axes, configure_plotting\n\nconfigure_plotting()\n\n  </pre>"},{"location":"s-a-1/#assignment-one","title":"Assignment one","text":"<p>The first assignment covers the content from weeks 1 and 2, which includes topics such as early atomic physics, the hydrogen atom, stationary perturbation theory, the variational principle, angular momentum coupling, and the Hyperfine effect.</p> <p> A pdf version of the assignment as distributed     </p>"},{"location":"s-a-1/#question-1","title":"Question 1","text":"<p>Tritium</p> <p>Tritium is an isotope of hydrogen, with a nucleus comprising one proton and two neutrons. The tritium nucleus (triton) is radioactive, decaying via \\(\\beta\\) emission to a helium-3 nucleus which comprises two protons and one neutron. An electron is initially in the ground state of a tritium atom. After the (instantaneous) \\(\\beta\\) decay, what is the probability that the electron is in the ground state of the new atom?</p> <p>The ground state of tritium (\\(Z=1\\)) is</p> \\[     \\psi_{T,100}(r, \\theta, \\phi) = \\frac{1}{\\sqrt{\\pi a_0^3}} e^{-r/a_0} \\] <p>and the ground state of helium-3 (\\(Z=2\\)) is</p> \\[     \\psi_{He,100}(r, \\theta, \\phi) = \\sqrt{\\frac{8}{\\pi a_0^3}} e^{-2r/a_0}. \\] <p>The wavefunction is unchanged during the decay, so we can compute the probability via the usual way, namely:</p> \\[     \\mathscr{P}(\\psi = \\psi_{He,100}) = \\left\\rvert \\left\\langle \\psi_{He,100} \\rvert \\psi_{T,100} \\right\\rangle \\right\\rvert^2. \\] <p>The inner product is</p> \\[\\begin{align*}     \\left\\langle \\psi_{He,100} \\rvert \\psi_{T,100} \\right\\rangle &amp; = \\int \\psi_{He,100} \\, \\psi_{T,100} \\, dV \\\\     &amp; = \\int_0^\\infty \\int_0^{2\\pi} \\int_0^\\pi \\sqrt{\\frac{8}{\\pi a_0^3}} e^{-2r/a_0} \\frac{1}{\\sqrt{\\pi a_0^3}} e^{-r/a_0} r^2 \\sin(\\theta) \\, d\\theta \\, d\\phi \\, dr \\\\     &amp; = \\frac{\\sqrt{8}}{\\pi a_0^3} (4\\pi) \\int_0^\\infty r^2 e^{-3r/a_0} dr = \\frac{4\\sqrt{8}}{a_0^3} \\left(\\frac{2a_0^3}{27}\\right) \\\\     &amp; = \\frac{8\\sqrt{8}}{27} \\end{align*}\\] <p>and therefore the probability is</p> \\[     \\mathscr{P}(\\psi = \\psi_{He,100}) = \\left\\rvert  \\frac{8\\sqrt{8}}{27} \\right\\rvert^2 \\approx 0.702 \\]"},{"location":"s-a-1/#question-2","title":"Question 2","text":"<p>Muonic hyrdogen</p> <p>Muons are effectively heavy electrons. They rapidly decay into electrons with a lifetime of approximately \\(2.2~\\mu\\textrm{s}\\) - see the lifetime of the muon experiment in third year labs - but through some technical wizardry, it is possible to produce muonic hydrogen and perform precision spectroscopy on these atoms before they decay. Indeed, said spectroscopy has led to a still-unanswered problem, the so-called proton radius problem.</p> <p>As muons are much heavier than electrons, muonic hydrogen is a much smaller atom the vanilla hydrogen. As such, the finite size of the nucleus plays an more significant role in the energy-level structure of the system. The effective Coulomb potential can be approximated as</p> \\[     V(r) =     \\begin{cases}         -\\frac{Z e^2}{r} &amp; r \\geq R \\\\          -\\frac{Z e^2}{r}\\left( \\frac{3}{2}-\\frac{1}{2}\\frac{r^2}{R^2} \\right) &amp; r \\leq R     \\end{cases} \\] <p>where \\(R\\) is the region over which the nuclear charge is distributed.</p> <ol> <li>Express the Hamiltonian for muonic hydrogen as a perturbation of a hydrogenic system.          </li> <li>Posit how the energies for all the states with \\(n=1, 2,\\) and \\(3\\) will be shifted. How will the levels be shifted relative to absolutely, and relatively? Draw an energy-level diagram, indicating the unperturbed states, the perturbed states, and discuss the physical origins of any differences between states.</li> <li>Calculate the first-order change in energy for the ground state of muonic hydrogen. You can make the approximation that \\(R \\ll a_\\mu\\), where \\(a_\\mu\\) is the Bohr radius for the muon (1).</li> <li>The charge radius \\(R\\) is often measured by probing the \\(2s \\rightarrow 2p\\) transition. Find an expression for the (angular) frequency of this transition, thus showing one can indeed measure \\(R\\) from measurement of this transition.</li> <li>Can you suggest reasons that the \\(2s \\rightarrow 2p\\) transition is used to measure \\(R\\) instead of directly measuring the ground state energy?</li> </ol> <ol> <li>Hint: make this approximation early!</li> </ol>"},{"location":"s-a-1/#21","title":"2.1","text":"<p>Express the Hamiltonian for muonic hydrogen as a perturbation of a hydrogenic system.  </p> <p>If the system were ideal, that is, the proton charge radius was zero, the potential would be \\(V_0 = -\\frac{Z e^2}{r}\\) for all \\(r\\) - which we know how to solve. Our perturbation can then be constructed by considering \\(H'=V - V_0\\), or explicitly</p> \\[     H^\\prime =     \\begin{cases}         0 &amp; r \\ge R \\\\         Z e^2 \\left[\\frac{1}{r}-\\frac{1}{R}\\left(\\frac{3}{2} - \\frac{1}{2}\\frac{r^2}{R^2}\\right)\\right] &amp; r \\le R     \\end{cases} \\]"},{"location":"s-a-1/#22","title":"2.2","text":"<p>Posit how the energies for all the states with \\(n=1, 2,\\) and \\(3\\) will be shifted. How will the levels be shifted relative to absolutely, and relatively? Draw an energy-level diagram, indicating the unperturbed states, the perturbed states, and discuss the physical origins of any differences between states.</p> <p>When \\(r &lt; R\\), \\(H^\\prime &gt; 0\\) and the energy levels shift upwards, which is best understood through Gauss' law: inside the charge radius, there is less enclosed charge, so the interaction will be lessened and therefore the muon will be more weakly bound. This effect will be greatest for states which have a higher likelihood of being closer to the nucleus (\\(n=1\\)) and the effect will diminish with increasing angular momentum \\(\\ell\\), as states are further from the origin. We therefore expect the greatest effects for low \\(n\\) and \\(l\\), with the perturbation diminishing for higher \\(n\\) and \\(l\\).</p> <p> </p> The energy levels of muonic hydrogen"},{"location":"s-a-1/#23","title":"2.3","text":"<p>Calculate the first-order change in energy for the ground state of muonic hydrogen. You can make the approximation that \\(R \\ll a_\\mu\\), where \\(a_\\mu\\) is the Bohr radius for the muon (1).</p> <ol> <li>Hint: make this approximation early!</li> </ol> <p>The first-order correction to the ground state is given by</p> \\[     E_{1s}^{(1)} = \\left\\langle 1s \\left\\rvert H^\\prime \\right\\rvert 1s \\right\\rangle \\] <p>The ground state in position space is given by \\(\\psi_{\\mu,100} = \\frac{1}{\\sqrt{\\pi a_\\mu^3}} e^{-r/a_{\\mu}}\\) so making the approximation that \\(e^{-r/a_\\mu}\\approx 1\\) since \\(R \\ll a_\\mu\\) (I told you to make the approximation early!)</p> \\[   E_{1s}^{(1)} = \\int \\psi_{\\mu,100}^* \\, H' \\, \\psi_{\\mu,100} d\\mathbf{r} = \\frac{1}{\\pi a_\\mu^3} (4\\pi) \\int_0^R  Z e^2 \\left[\\frac{1}{r}-\\frac{1}{R}\\left(\\frac{3}{2} - \\frac{1}{2}\\frac{r^2}{R^2}\\right)\\right] r^2 dr \\] <p>where we note that the angular integral simply evaluates to \\(4\\pi\\) as there is no dependence on \\(\\theta\\) or \\(\\phi\\). Cranking the handle:</p> \\[\\begin{align*}     \\frac{ 4 Z e^2 }{a_\\mu^3} \\left(\\frac{R^2}{2}-\\frac{R^3}{2R} + \\frac{R^5}{10 R^3} \\right) &amp; = \\frac{ 4 Z e^2 }{a_\\mu^3} \\left(\\frac{R^2}{2}-\\frac{R^2}{2} + \\frac{R^2}{10} \\right) \\\\     &amp; = \\frac{ 2 R^2 Z e^2 }{5 a_\\mu^3} \\end{align*}\\]"},{"location":"s-a-1/#24","title":"2.4","text":"<p>The charge radius \\(R\\) is often measured by probing the \\(2s \\rightarrow 2p\\) transition. Find an expression for the (angular) frequency of this transition, thus showing one can indeed measure \\(R\\) from measurement of this transition.</p> <p>We follow essentially an identical procedure to that above, except using the states \\(\\psi_{\\mu,200}\\) and \\(\\psi_{\\mu,210}\\). Once you have played the game long enough, you can be sneaky, identifying that in integral over \\(\\psi_{\\mu,210}\\) is going to vanish, as the only angular dependence of the wave function is \\(\\cos(\\theta)\\), and the perturbing Hamiltonian does not have angular dependence, so we will effectively compute the integral of \\(\\cos^2(\\theta)\\sin(\\theta)\\) which when integrated over \\([0,2\\pi]\\) will average to zero, so we can immediately say that \\(E_{2p}^{(1)}=0\\).</p> <p>Computing \\(E_{2s}^{(1)}\\), we have</p> \\[ \\psi_{\\mu,200} = \\frac{1}{\\sqrt{\\pi}}\\left(\\frac{1}{2 a_\\mu}\\right)^{3/2} \\left[1-\\frac{r}{2 a_\\mu}\\right] e^{-r/a_{\\mu}} \\] <p>and again, making the approximation that \\(e^{-r/a_\\mu}\\approx 1\\) since \\(R \\ll a_\\mu\\) means we end up computing effectively the same as above</p> \\[\\begin{align*}     E_{2s}^{(1)} = \\int \\psi_{\\mu,200}^* \\, H' \\, \\psi_{\\mu,200} d\\mathbf{r} &amp; =  \\frac{1}{8 \\pi a_\\mu^3} (4\\pi) \\int_0^R  Z e^2 \\left[\\frac{1}{r}-\\frac{1}{R}\\left(\\frac{3}{2} - \\frac{1}{2}\\frac{r^2}{R^2}\\right)\\right] r^2 dr \\\\     &amp; = \\frac{Ze^2}{2 a_\\mu^3} \\frac{R^2}{10} \\\\     &amp; = \\frac{R^2 Z e^2 }{20 a_\\mu^3} \\end{align*}\\] <p>And so the perturbation to the energy of the transition is given by</p> \\[ \\Delta E = E_{2p}^{(1)} - E_{2s}^{(1)} \\approx E_{2s}^{(1)} \\] <p>and the total energy of the transition \\(E=\\hbar\\omega=E_{2p}-E_{2s}\\) to first-order only has the correction \\(E_{2s}^{(1)}\\)</p>"},{"location":"s-a-1/#25","title":"2.5","text":"<p>Can you suggest reasons that the \\(2s \\rightarrow 2p\\) transition is used to measure \\(R\\) instead of directly measuring the ground state energy?</p> <p>This is very much an experimentally-oriented question, and there are a few main considerations. The first is what happens when when measures a ground-state energy: when you do spectroscopy, you put in a photon with enough energy to drive the transition. By definition, the ground-state energy is the same as the ionisation energy of the atom, so you will generate muons in the spectroscopy process, which has the disadvantage of destroying your hard-won muonic hydrogen, but also means that you now have charge available to perturb the energy levels of surrounding atoms. There is also the practical consideration of when we perform spectroscopy, we like microwaves and optical frequencies, as we can control the frequencies of both of these very well. In muonic hydrogen, the energies involved are much larger than those of hydrogen - see the energy-level diagram below - and producing monochromatic radiation at those wavelengths is hard! Explicitly, experiments which deal even with the \\(1s\\rightarrow2p\\) states in hydrogen are hard work, as you require a laser in the UV, and these are both hard to make and difficult to use. In the case of muonic hydrogen, you require 2keV X-rays for the same transition, and coherent sources of X-rays are not readily available.</p> <p> </p> The energy levels of both electronic hydrogen and muonic hydrogen, taken from the paper The proton size which gives a good account of the *proton radius puzzle*. <p>For the \\(2s\\rightarrow2p\\) transition in hydrogen, we can use microwaves to drive transitions, which corresponds to deep infrared transitions for muonic hydrogen, but whilst this is not the most convenient laser wavelegnth, we can make it, and therefore do precision spectroscopy of muonic hydrogen. Well, for the time it exists before the muon decays!</p>"},{"location":"s-a-1/#question-3","title":"Question 3","text":"<p>Variational method</p> <p>Electrons in many-electron atoms generally experience a screened potential, that is, a potential that is smaller in magnitude than that due solely to its interaction with the nucleus due to other electrons shielding the nuclear charge.</p> <p>In atomic units, we can model this screened potential using</p> \\[     V(r) = -\\frac{Z}{r} + \\frac{1 - e^{-\\mu r}}{r} \\] <p>where \\(\\mu\\) (1) is a constant determined by atomic properties. We are going to use our intuition and propose a trial wave function for the ground state of the form</p> \\[ \\psi_{trial}(\\mathbf{r}) \\propto e^{-\\lambda Z r} Y_0^0(\\theta, \\phi) \\] <p>You are going to use the variational method to find a bound on the ground-state energy.</p> <ol> <li>Determined the normalisation constant for the trail wave function \\psi_{trial}(\\mathbf{r})</li> <li>Calculate the expectation value \\(\\left\\langle \\psi_{trial} \\rvert T \\rvert\\psi_{trial} \\right\\rangle\\), where \\(T\\) is the kinetic energy operator</li> <li>Calculate the expectation value \\(\\left\\langle \\psi_{trial} \\rvert V_0 \\rvert \\psi_{trial} \\right\\rangle\\), where \\(V_0\\) is the normal Coulomb potential</li> <li>Calculate the expectation value \\(\\left\\langle \\psi_{trial} \\rvert V^\\prime \\rvert \\psi_{trial} \\right\\rangle\\), where \\(V^\\prime\\) is perturbation from the normal Coulomb potential</li> <li>Using the above, calculate a bound on the ground state energy of the system, assuming a screening potential of \\(\\mu = 0.1~\\text{a.u.}^{-1}\\). You may solve non-trivial polynomials computationally (indeed, it is encouraged) but ensure to include executable code in your response.</li> </ol> <ol> <li>The symbol \\(\\mu\\) here is convention, and is unfortunate given the question above, but the two \\(\\mu\\) are very much unrelated!</li> </ol>"},{"location":"s-a-1/#31","title":"3.1","text":"<p>Determined the normalisation constant for the trail wave function \\(\\psi_{trial}(\\mathbf{r})\\)</p> <p>If we have our trial wave function</p> \\[     \\psi_{trial}(\\mathbf{r}) = N e^{-\\lambda Z r} Y_0^0(\\theta, \\phi) = \\frac{N}{\\sqrt{4\\pi}} e^{-\\lambda Z r} \\] <p>then normailsation demands that \\(\\left \\langle \\psi_{trial} \\rvert \\psi_{trial} \\right\\rangle = 1\\). This means that</p> \\[     \\begin{align*}           1 = \\left \\langle \\psi_{trial} \\rvert \\psi_{trial} \\right\\rangle &amp; = \\frac{N^2}{4\\pi}\\int_0^\\infty 4\\pi r^2 e^{-2\\lambda Z r} dr \\\\           &amp; = N^2\\frac{2!}{(2\\lambda Z)^3} = \\frac{N^2}{4(\\lambda Z)^3} \\\\           &amp; \\Rightarrow N^2 = 4(\\lambda Z)^3     \\end{align*} \\]"},{"location":"s-a-1/#32","title":"3.2","text":"<p>Calculate the expectation value \\(\\left\\langle \\psi_{trial} \\rvert T \\rvert\\psi_{trial} \\right\\rangle\\), where \\(T\\) is the kinetic energy operator</p> <p>To calculate the expectation value \\(\\langle T \\rangle\\), we must compute \\(\\left \\langle \\psi_{trial} \\rvert T \\rvert \\psi_{trial} \\right\\rangle\\). As we are in atomic units, this means out kinetic energy operator for a wave function which depends only on \\(r\\) has the form</p> \\[     T=- \\frac{1}{2} \\nabla^2 = -\\frac{1}{2}\\frac{1}{r^2}\\frac{\\partial}{\\partial r}\\left(r^2\\frac{\\partial}{\\partial r}\\right) \\] <p>which when applied to our wave function</p> \\[   \\begin{align*}       T\\rvert \\psi_{trial} \\rangle &amp; = -\\frac{1}{2}\\frac{1}{r^2}\\frac{\\partial}{\\partial r}\\left(r^2\\frac{\\partial}{\\partial r} \\frac{N}{\\sqrt{4\\pi}} e^{-\\lambda Z r} \\right) \\\\       &amp; = \\frac{\\lambda Z N}{2\\sqrt{4\\pi}} \\frac{1}{r^2} \\frac{\\partial}{\\partial r} \\left( r^2 e^{-\\lambda Z r} \\right) \\\\       &amp; = \\frac{\\lambda Z N}{2\\sqrt{4\\pi}} \\frac{1}{r^2}\\left(2re^{-\\lambda Z r} - \\lambda Z r^2 e^{-\\lambda Z r}\\right) \\\\       \\Rightarrow \\left\\langle \\psi_{trial} \\rvert T \\rvert \\psi_{trial} \\right\\rangle &amp; = \\frac{\\lambda Z N^2}{2\\cdot4\\pi} \\int_0^\\infty (4\\pi) \\left(2re^{-\\lambda Z r} - \\lambda Z r^2 e^{-\\lambda Z r}\\right) dr \\\\       &amp; = \\frac{\\lambda Z N^2}{2}\\left(2\\frac{1!}{(2\\lambda Z)^2} - \\lambda Z \\frac{2!}{(2\\lambda Z)^3}\\right) \\\\       &amp; = \\frac{\\lambda Z N^2}{2}\\frac{1}{4(\\lambda Z)^2} = \\frac{N^2}{8\\lambda Z} \\\\       &amp; \\left( = \\frac{(\\lambda Z)^2}{2} \\right)   \\end{align*} \\] <p>where I normally not substitute \\(N\\) until the computation is complete, but I put the result there if those that use a wave function with a normalisation constant. This is probably worth more than two marks...</p>"},{"location":"s-a-1/#33","title":"3.3","text":"<p>Calculate the expectation value \\(\\left\\langle \\psi_{trial} \\rvert V_0 \\rvert \\psi_{trial} \\right\\rangle\\), where \\(V_0\\) is the normal Coulomb potential</p> <p>After the work above, this one is easy! In atomic units, we need only compute \\(\\left\\langle \\psi_{trial} \\rvert -Z/r \\rvert \\psi_{trial} \\right\\rangle\\) which we can do directly, in the same way as the integrals above:</p> \\[\\begin{align*}     \\left\\langle \\psi_{trial} \\rvert V_0 \\rvert \\psi_{trial} \\right\\rangle &amp; = \\frac{N^2}{4\\pi}(4\\pi)\\int_0^\\infty -Z r e^{-2\\lambda Z r}dr \\\\     &amp; = - N^2 Z \\frac{1!}{(2\\lambda Z)^2} \\\\     &amp; = - \\frac{ZN^2}{(2\\lambda Z)^2} \\end{align*}\\]"},{"location":"s-a-1/#34","title":"3.4","text":"<p>Calculate the expectation value \\(\\left\\langle \\psi_{trial} \\rvert V^\\prime \\rvert \\psi_{trial} \\right\\rangle\\), where \\(V^\\prime\\) is perturbation from the normal Coulomb potential</p> <p>Hopefully it was clear that this didn't want you to calculate the expectation value of the full screening potential, just the perturbation, namely</p> \\[ V^\\prime = \\frac{1 - e^{-\\mu r}}{r} \\] <p>The expectation value is then</p> \\[\\begin{align*}     \\left\\langle \\psi_{trial} \\rvert V^\\prime \\rvert \\psi_{trial} \\right\\rangle &amp; = \\frac{N^2}{4\\pi}(4\\pi)\\int_0^\\infty r^2 e^{-2\\lambda Z r}  \\frac{1 - e^{-\\mu r}}{r} dr \\\\     &amp; = N^2 \\left( \\int_0^\\infty r e^{-2\\lambda Z r} dr - \\int_0^\\infty r e^{-(2\\lambda Z+\\mu) r} dr \\right) \\\\     &amp; = N^2 \\left( \\frac{1}{(2\\lambda Z)^2} - \\frac{1}{(2\\lambda Z+\\mu)^2}  \\right) \\\\ \\end{align*}\\] <p>This could be rearranged, but that is what we are going to do in the final part of this question.</p>"},{"location":"s-a-1/#35","title":"3.5","text":"<p>Using the above, calculate a bound on the ground state energy of the system, assuming a screening potential of \\(\\mu = 0.1~\\textrm{a.u.}^{-1}\\). You may solve non-trivial polynomials computationally (indeed, it is encouraged) but ensure to include executable code in your response.</p> <p>Incorrect value of \\(\\mu\\)</p> <p>It should be noted that there was an error in this question: the exponent in the value of \\(\\mu\\) was not rendered in the pdf version of the assignment. Given typical values are of the order 0.01 to 0.1 in atomic units, a value of \\(10~\\textrm{m}^{-1}\\) is silly. In any case, for the bulk of the question \\(mu\\) is just a symbol, and for any computations, there will be no penalty if the stated value - or any other - is used.   </p> <p>To find a bound on the energy, we can apply the variational principle, which states that the ground state energy will be less than the expectation value</p> \\[     \\left\\langle \\psi_{trial} \\rvert H \\rvert \\psi_{trial} \\right\\rangle \\] <p>Our Hamiltonian is composed by \\(H = T + V_0 + V^\\prime\\), and as taking the expectation value is a linear operation, the required expectation value is the sum of the individual expectation values, which we have just computed. Therefore</p> \\[\\begin{align*}     \\left\\langle H \\right\\rangle &amp; = N^2 \\left( \\frac{1}{8\\lambda Z} - \\frac{Z}{(2\\lambda Z)^2} + \\frac{1}{(2\\lambda Z)^2} - \\frac{1}{(2\\lambda Z+\\mu)^2} \\right) \\\\     &amp; = 4(\\lambda Z)^3 \\left( \\frac{1}{8\\lambda Z} + \\frac{1-Z}{(2\\lambda Z)^2} - \\frac{1}{(2\\lambda Z+\\mu)^2} \\right) \\end{align*}\\] <p>We now seek to minimise this with respect to our variational parameter \\(\\lambda\\), which means that we need to compute the derivative with respect to \\(\\lambda\\) and set it to zero. As each instance of \\(\\lambda\\) appears in the form of \\(\\lambda Z\\), I am going to define a new variable \\(\\lambda^\\prime = \\lambda Z\\) just to streamline things. We could have actually stated the calculation with this redefinition, as this means that our variational parameter would directly be an effective charge, rather than the correction factor to take the full charge to the effective charge. In any case, computing the derivative:</p> \\[\\begin{align*}     \\frac{\\partial \\left\\langle H \\right\\rangle}{\\partial \\lambda^\\prime} &amp; = \\frac{\\partial}{\\partial \\lambda^\\prime} \\left( \\frac{\\lambda^\\prime}{2} + (1-Z)\\lambda^\\prime - \\frac{4\\lambda^\\prime}{(2\\lambda^\\prime + \\mu)^2} \\right) \\\\     &amp; = \\lambda^\\prime + (1-Z) + \\frac{4{\\lambda^\\prime}^2(2\\lambda^\\prime+3\\mu)}{(2\\lambda^\\prime+\\mu)^3} \\end{align*}\\] <p>and we need to find the roots. Ain't nobody got time for that analytically, so let go to the computer. Normally I would only ever discuss <code>python</code>, but for a little exposure, I am going to highlight that sometimes <code>Mathematica</code> can be very useful - provided that you can get access to it.</p> <p>With that said, using <code>Mathematica</code>, one is able to get an analytic form to the roots by simply asking it to find them for you:</p> <pre><code>sols = Solve[x + (1 - Z) + (4 x^2 (2 x + 3 m))/(2 x + m)^3 == 0, x] /. {m -&gt; 0.1}\n</code></pre> <p>and one will be treated to a torrent of terms. Notably, there will be multiple solutions - this is fine, we are most interested in the term which will minimise the energy. <code>Mathematica</code> can tell you the energy of these states if you specify the expectation value, e.g.</p> <pre><code>4 x^2 (1/(8 x) + (1 - Z)/(2 x)^2  - 1/(2 x - 0.1)^2) /. {sols}\n</code></pre> <p>Once again, you will be treated to a bunch of garbage, but these are your solutions. This becomes more meaningful once on actually specifies a value for \\(Z\\), so for the sake of completeness, let us look at Helium, where \\(Z=2\\), which returns a minimum value of \\(E = -3.14~\\textrm{a.u.} = -85.4~\\textrm{eV}\\). This shielding parameter was just chosen at random with the correct order of magnitude (lol) so the result is not the meaningful by itself.</p> <p>If one wanted to use <code>python</code>, a good bet would be to use the <code>solve</code> function from the <code>SciPy.optimize</code> module:</p> <pre><code>import numpy as np\nfrom scipy.optimize import fsolve\n\n# Define the expectation value derivative\ndef expectation_min(lambda_prime, Z, mu):\n   return lambda_prime + (1-Z) + (4*lambda_prime**2*(2*lambda_prime + 3*mu)) / ((2*lambda_prime + mu)**3)\n\n# Set values of Z and mu\nZ_value = 2  # Helium\nmu_value = 0.1  # screening constant [a.u.]\n\n# Initial value for lambda_prime\nlambda_guess = 100 # The solution shouldn't be overly sensitive to this\n\n# Solve and print the solution\nnumerical_solution = fsolve(expectation_min, lambda_guess, args=(Z_value, mu_value))\nprint(numerical_solution)\n</code></pre> <p>which yield the identical result to that of <code>Mathematica</code>.</p>"},{"location":"s-a-1/#question-4","title":"Question 4","text":"<p>Angular momentum</p> <p>In class, we used the fact that the electron and proton spin observables \\(\\mathbf{S}^2\\) and \\(\\mathbf{I}^2\\) commute with the hyperfine Hamiltonian \\(H_{hf}^\\prime = A\\mathbf{S}\\cdot\\mathbf{I}/\\hbar^2\\), and stated that the component observables \\(S_z\\) and \\(I_z\\) do not.</p> <ol> <li>Explicitly show that \\(\\mathbf{S}^2\\) and \\(\\mathbf{I}^2\\) commute with the hyperfine Hamiltonian</li> <li>Explicitly show that \\(S_z\\) and \\(I_z\\) do not commute with the hyperfine Hamiltonian</li> </ol> <p>Commutation relations</p> <p>For both questions, we make use of the standard angular momentum commutation relations:</p> \\[\\begin{gather*}     \\left[ \\mathbf{J}^2, J_{x,y,z} \\right] = 0 \\\\     \\left[J_i, J_j\\right] = i\\hbar\\varepsilon_{ijk}J_k \\end{gather*}\\] <p>where \\(\\varepsilon_{ijk}\\) is the Levi-Civita symbol.</p>"},{"location":"s-a-1/#41","title":"4.1","text":"<p>Explicitly show that \\(\\mathbf{S}^2\\) and \\(\\mathbf{I}^2\\) commute with the hyperfine Hamiltonian</p> <p>To show the operators commute, we crank the handle. Starting with \\(\\mathbf{S}^2\\):</p> \\[   \\begin{align*}       \\left[H_{h f}^{\\prime}, \\mathbf{S}^2\\right] &amp; =\\left[\\frac{A}{\\hbar^2} \\mathbf{S} \\cdot \\mathbf{I}, \\mathbf{S}^2\\right]=\\frac{A}{\\hbar^2} \\mathbf{I}\\left[\\mathbf{S}, \\mathbf{S}^2\\right]=\\frac{A}{\\hbar^2} \\mathbf{I} \\cdot\\left[S_x \\mathbf{i}+S_y \\mathbf{j}+S_z \\mathbf{k}, \\mathbf{S}^2\\right] \\\\       &amp; = \\frac{A}{\\hbar^2} \\mathbf{I} \\cdot\\left\\{\\mathbf{i}\\left[S_x, \\mathbf{S}^2\\right]+\\mathbf{j}\\left[S_y, \\mathbf{S}^2\\right]+\\mathbf{k}\\left[S_z, \\mathbf{S}^2\\right]\\right\\}=0 \\\\   \\end{align*} \\] <p>and then \\(\\mathbf{I}^2\\):</p> \\[   \\begin{align*}       {\\left[H_{h f}^{\\prime}, \\mathbf{I}^2\\right] } &amp; =\\left[\\frac{A}{\\hbar^2} \\mathbf{S} \\cdot \\mathbf{I}, \\mathbf{I}^2\\right]=\\frac{A}{\\hbar^2} \\mathbf{S} \\cdot\\left[\\mathbf{I}, \\mathbf{I}^2\\right]=\\frac{A}{\\hbar^2} \\mathbf{S} \\cdot\\left[I_x \\mathbf{i}+I_y \\mathbf{j}+I_z \\mathbf{k}, \\mathbf{I}^2\\right]= \\\\       &amp; =\\frac{A}{\\hbar^2} \\mathbf{S} \\cdot\\left\\{\\mathbf{i}\\left[I_x, \\mathbf{I}^2\\right]+\\mathbf{j}\\left[I_y, \\mathbf{I}^2\\right]+\\mathbf{k}\\left[I_z, \\mathbf{I}^2\\right]\\right\\}=0 \\\\   \\end{align*} \\]"},{"location":"s-a-1/#42","title":"4.2","text":"<p>Explicitly show that \\(S_z\\) and \\(I_z\\) do not commute with the hyperfine Hamiltonian</p> <p>In the same way as above, we can show the operators do not commute directly:</p> \\[   \\begin{align*}       {\\left[H_{h f}^{\\prime}, S_z\\right] } &amp; =\\left[\\frac{A}{\\hbar^2} \\mathbf{S} \\cdot \\mathbf{I}, S_z\\right]=\\frac{A}{\\hbar^2}\\left[S_x I_x+S_y I_y+S_z I_z, S_z\\right] \\\\       &amp; =\\frac{A}{\\hbar^2}\\left\\{I_x\\left[S_x, S_z\\right]+I_y\\left[S_y, S_z\\right]+I_z\\left[S_z, S_z\\right]\\right\\} \\\\       &amp; =\\frac{A}{\\hbar^2}\\left\\{-i \\hbar S_y I_x+i \\hbar S_x I_y\\right\\}=\\frac{-i A}{\\hbar}\\left\\{S_y I_x-S_x I_y\\right\\} \\neq 0 \\\\       {\\left[H_{h f}^{\\prime}, I_z\\right] } &amp; =\\left[\\frac{A}{\\hbar^2} \\mathbf{S} \\cdot \\mathbf{I}, I_z\\right]=\\frac{A}{\\hbar^2}\\left[S_x I_x+S_y I_y+S_z I_z, I_z\\right] \\\\       &amp; =\\frac{A}{\\hbar^2}\\left\\{S_x\\left[I_x, I_z\\right]+S_y\\left[I_y, I_z\\right]+S_z\\left[I_z, I_z\\right]\\right\\} \\\\       &amp; =\\frac{A}{\\hbar^2}\\left\\{-i \\hbar I_y S_x+i \\hbar I_x S_y\\right\\}=\\frac{-i A}{\\hbar}\\left\\{I_y S_x-I_x S_y\\right\\} \\neq 0   \\end{align*} \\]"},{"location":"s-a-1/#question-5","title":"Question 5","text":"<p>Positronium</p> <p>In February 2024, positronium was laser cooled, heralding the era for precision measurements involving antimatter. Positronium atom is a hydrogen-like atom with a positron (\\(m = m_e,\\,q = +e\\), spin 1/2)  as the nucleus and a bound electron. The hyperfine structure in the ground state of positronium is described by a perturbation Hamiltonian \\(H^\\prime = A \\mathbf{S}_1 \\cdot \\mathbf{S}_2/\\hbar^2\\) where \\(\\mathbf{S}_i\\) are the spins of the electron and positron.</p> <ol> <li>What is the Bohr energy of the ground state of positronium (you can ignore the hyperfine structure for this one)?</li> <li>The electron and positron spins can be coupled to form the total spin \\(\\mathbf{S}\\) of the atom. Write down the spin states of the coupled and uncoupled bases and how they relate to each other.</li> <li>Express the hyperfine Hamiltonian in the ground state as a matrix in both the coupled and uncoupled spin bases.</li> <li>Determine the effect of the hyperfine perturbation interaction on the ground state of positronium. Draw an energy level diagram to illustrate your results.</li> </ol>"},{"location":"s-a-1/#51","title":"5.1","text":"<p>What is the Bohr energy of the ground state of positronium (that is, you can ignore the hyperfine structure)?</p> <p>The energy structure for hydrogen is given by \\(E_n = - \\alpha^2 \\mu c^2 / 2n\\) where \\(\\mu\\) is the reduced mass, which most of the time can be approximated by \\(m_e\\), but for positronium, as the nuclear mass and electron mass are the same, the reduced mass will no longer be well approximated by \\(m_e\\). Explicitly</p> \\[     \\mu = \\frac{m_e m_n}{m_e + m_n} = \\frac{m_e^2}{2m_e} = \\frac{m_e}{2} \\] <p>so the energy levels in hydrogen are essentially half those of hydrogen, meaning that the ground state energy is</p> \\[     E_1 = -\\frac{13.6}{2} = - 6.8~\\textrm{eV} \\]"},{"location":"s-a-1/#52","title":"5.2","text":"<p>The electron and positron spins can be coupled to form the total spin \\(\\mathbf{S}\\) of the atom. Write down the spin states of the coupled and uncoupled bases and how they relate to each other.</p> <p>In the same way as the electron and proton in hydrogen are two spin-1/2 particles, as are the electron and positron in positronium.</p> <p>The uncoupled basis states \\(\\rvert \\frac{1}{2} \\frac{1}{2} m_{s_1} m_{s_2} \\rangle\\) are</p> \\[   \\left\\rvert ++ \\right\\rangle, \\left\\rvert +- \\right\\rangle, \\left\\rvert -+ \\right\\rangle, \\, \\mathrm{and} \\, \\left\\rvert -- \\right\\rangle \\] <p>and the coupled states are</p> \\[   \\begin{alignedat}{2}       &amp;\\left.\\begin{aligned}           &amp; |11\\rangle = |++\\rangle \\\\           &amp; |10\\rangle = \\frac{1}{\\sqrt{2}}\\left[|+-\\rangle+|-+\\rangle\\right] \\\\           &amp; |1,-1\\rangle = |--\\rangle       \\end{aligned}       \\quad \\right\\rbrace       &amp; \\quad \\text{Triplet state} \\\\[10pt]       &amp;\\left.\\begin{aligned}           &amp; |00\\rangle = \\frac{1}{\\sqrt{2}}\\left[|+-\\rangle-|-+\\rangle\\right]       \\end{aligned}       \\right\\rbrace       &amp; \\quad \\text{Singlet state}   \\end{alignedat} \\]"},{"location":"s-a-1/#53","title":"5.3","text":"<p>Express the hyperfine Hamiltonian in the ground state as a matrix in both the coupled and uncoupled spin bases.</p> <p>The hyperfine Hamiltonian is</p> \\[   \\begin{align*}       \\mathbf{S} &amp; = \\mathbf{S}_1 + \\mathbf{S}_2 \\\\       \\mathbf{S}^2 &amp; = (\\mathbf{S}_1 + \\mathbf{S}_2)^2 = \\mathbf{S}_1^2 + \\mathbf{S}_2^2 + 2 \\mathbf{S}_1 \\cdot \\mathbf{S}_2 \\\\       \\Rightarrow \\mathbf{S}_1 \\cdot \\mathbf{S}_2 &amp; = \\frac{1}{2} \\left( \\mathbf{S}^2 - \\mathbf{S}_1^2 - \\mathbf{S}_2^2 \\right) = \\frac{1}{2}\\hbar^2 \\left( S(S+1) - 3/4 \\right) \\\\       H^\\prime &amp; = A \\mathbf{S}_1\\cdot\\mathbf{S_2} = \\frac{A}{2}\\hbar^2 \\left( S(S+1) - 3/4 \\right)   \\end{align*} \\] <p>The matrix in the coupled basis is then</p> \\[     H^\\prime = \\frac{A\\hbar^2}{4}     \\begin{pmatrix}         1 &amp; 0 &amp; 0 &amp; 0 \\\\         0 &amp; 1 &amp; 0 &amp; 0 \\\\         0 &amp; 0 &amp; 1 &amp; 0 \\\\         0 &amp; 0 &amp; 0 &amp; -3     \\end{pmatrix}     \\begin{matrix}         \\ket{11} \\\\         \\ket{10} \\\\         \\ket{1,-1} \\\\         \\ket{00}     \\end{matrix} \\] <p>To calculate the matrix in the uncoupled basis, we can express the \\(x\\) and \\(y\\) components of \\(\\mathbf{S}_1\\) and \\(\\mathbf{S}_2\\) in terms of ladder operators</p> \\[     \\mathbf{S}_1 \\cdot \\mathbf{S}_2 = S_{1x}S_{2x} + S_{1y}S_{2y} + S_{1z}S_{2z} = \\frac{1}{2}\\left(S_{1+}S_{2-}+S_{1-}S_{2+}\\right) + S_{1z}S_{2z} \\] <p>and so</p> \\[     H^\\prime = \\frac{A\\hbar^2}{4}     \\begin{pmatrix}         1 &amp; 0 &amp; 0 &amp; 0 \\\\         0 &amp; -1 &amp; 2 &amp; 0 \\\\         0 &amp; 2 &amp; -1 &amp; 0 \\\\         0 &amp; 0 &amp; 0 &amp; 1     \\end{pmatrix}     \\begin{matrix}         \\left\\rvert ++ \\right\\rangle \\\\         \\left\\rvert +- \\right\\rangle \\\\         \\left\\rvert -+ \\right\\rangle \\\\         \\left\\rvert -- \\right\\rangle     \\end{matrix} \\]"},{"location":"s-a-1/#54","title":"5.4","text":"<p>Determine the effect of the hyperfine perturbation interaction on the ground state of positronium. Draw an energy level diagram to illustrate your results.</p> <p>Since the Hamiltonian in the coupled basis is diagonal</p> \\[   H^\\prime = A \\mathbf{S}_1\\cdot\\mathbf{S_2} = \\frac{A}{2}\\hbar^2 \\left( S(S+1) - 3/4 \\right) \\] <p>we can directly compute the energy eigenvalues</p> \\[    \\langle S^\\prime M^\\prime \\rvert H^\\prime \\rvert SM \\rangle = \\frac{1}{2} A \\hbar^2 \\left(S(S+1) - \\frac{3}{2}\\right) \\delta_{SS^\\prime} \\delta_{MM^\\prime}    =\\left\\{\\begin{array}{cc}            -\\frac{3}{4} A \\hbar^2 &amp; S=0 \\\\            \\frac{1}{4} A \\hbar^2 &amp; S=1            \\end{array}\\right. \\] <p>and so the energy-level structure is</p> <p> </p> A schematic of the Stern-Gerlach experiment"},{"location":"s-a-2/","title":"S a 2","text":"<pre>\n\nfrom matplotlib import pyplot\nimport numpy as np\n\nfrom common import draw_classic_axes, configure_plotting\n\nconfigure_plotting()\n\n  </pre>"},{"location":"s-a-2/#assignment-two","title":"Assignment two","text":"<p>The first assignment covers the content from weeks 3 and 4, which includes topics such as identical particles, transitions, the density matrix, and the optical Bloch equations.</p> <p> A .pdf version of the assignment as distributed     </p>"},{"location":"s-a-2/#question-1","title":"Question 1","text":"<p>Multiparticle harmonic oscillator</p> <p>Consider two non-interacting particles of mass \\(m\\) in the harmonic oscillator potential well. For the case with one particle in the single-particle state \\(\\ket{n}\\) and the other in state \\(\\ket{k}\\) (where \\(n \\ne k\\)), we are going to calculate the expectation value of the squared interparticle spacing: \\(\\left\\langle \\left( x_1 - x_2 \\right)^2 \\right\\rangle\\). Do this for the cases where the particles are:</p> <ul> <li>distinguishable</li> <li>spin-0</li> <li>spin-1/2 in a spin triplet state</li> </ul> <p>In all cases, calculate the expected interpatricle spacing and explain whether the results are consistent with your expectations, and why (1).</p> <ol> <li>Hint: Use Dirac notation. With the correct application, integration is not required for the above calculations. Go forth and harness the power of state vectors to improve your quality of life!</li> </ol> <p>For the astute observer, this problem is extremely similar to problem 4 from tutorial 3. Indeed, it is so similar that I can cut and paste a large amount of the \\(\\LaTeX\\) which I prepared for that solution.</p> <p><code>\\begin{Tutorial 3 problem 4 solution}</code></p> <p>We need to look at the three cases of the 2-particle wave function, which is a product of the two single-particle wave functions which are</p> <ul> <li>not symmetrised in the case of distinguishable particles</li> <li>symmetrised in the case of bosons</li> <li>antisymmetrised in the case of fermions</li> </ul> <p>with respect to exchange of the two particles. In the three cases, we have</p> \\[\\begin{align*}     &amp; \\left|\\psi_D\\right\\rangle=|n k\\rangle \\equiv|n\\rangle_1|k\\rangle_2 \\\\     &amp; \\left|\\psi_B\\right\\rangle=\\frac{1}{\\sqrt{2}}[|n k\\rangle+|k n\\rangle] \\\\     &amp; \\left|\\psi_F\\right\\rangle=\\frac{1}{\\sqrt{2}}[|n k\\rangle-|k n\\rangle] \\end{align*}\\] <p>where the single particle wave function \\(\\ket{n}=\\phi_n(x)=\\sqrt{\\frac{2}{L}}\\sin\\left(\\frac{n \\pi x}{L}\\right)\\).</p> <p>For distinguishable particles</p> \\[     \\left\\langle x_1^2\\right\\rangle_D=\\left\\langle n k\\left|x_1^2\\right| n k\\right\\rangle=\\left\\langle n\\left|x_1^2\\right| n\\right\\rangle\\langle k | k\\rangle=\\left\\langle x^2\\right\\rangle_n \\] <p>At this point, we can write down the integral, so</p> \\[     \\left\\langle x^2\\right\\rangle_n=\\int_0^L \\varphi_n^{+}(x) x^2 \\varphi_n(x) d x=\\int_0^L x^2\\left|\\varphi_n(x)\\right|^2 d x \\] <p>is a single-particle expectation value for \\(x^2\\). Likewise, we get</p> \\[   \\begin{gathered}       \\left\\langle x_2^2\\right\\rangle_D=\\left\\langle n k\\left|x_2^2\\right| n k\\right\\rangle=\\langle n | n\\rangle\\left\\langle k\\left|x_2^2\\right| k\\right\\rangle=\\left\\langle x^2\\right\\rangle_k \\\\       \\left\\langle x_1 x_2\\right\\rangle_D=\\left\\langle n k\\left|x_1 x_2\\right| n k\\right\\rangle=\\left\\langle n\\left|x_1\\right| n\\right\\rangle\\left\\langle k\\left|x_2\\right| k\\right\\rangle=\\langle x\\rangle_n\\langle x\\rangle_k \\\\       \\left\\langle\\left(x_1-x_2\\right)^2\\right\\rangle_D=\\left\\langle x^2\\right\\rangle_n+\\left\\langle x^2\\right\\rangle_k-2\\langle x\\rangle_n\\langle x\\rangle_k   \\end{gathered} \\] <p>So really, we need only perform the integrals to compute \\(\\left\\langle x^2\\right\\rangle_n\\) and \\(\\langle x\\rangle_n\\). But before we actually integrate, lets look at which integrals we need to compute in the case of fermions and bosons.</p> \\[\\begin{align*}       \\left\\langle x_1^2\\right\\rangle_{B, F} &amp; =\\frac{1}{\\sqrt{2}}\\left[\\langle n k| \\pm\\langle k n|\\right] x_1^2 \\times \\frac{1}{\\sqrt{2}}\\left[|n k\\rangle \\pm|k n\\rangle\\right] \\\\       &amp; =\\frac{1}{2}\\left[\\left\\langle n\\left|x_1^2\\right| n\\right\\rangle\\langle k | k\\rangle \\pm\\left\\langle n\\left|x_1^2\\right| k\\right\\rangle\\langle k | n\\rangle \\pm\\left\\langle k\\left|x_1^2\\right| n\\right\\rangle\\langle n | k\\rangle +\\left\\langle k\\left|x_1^2\\right| k\\right\\rangle\\langle n | n\\rangle\\right] \\\\       &amp; =\\frac{1}{2}\\left[\\left\\langle n\\left|x_1^2\\right| n\\right\\rangle \\pm 0 \\pm 0+\\left\\langle k\\left|x_1^2\\right| k\\right\\rangle\\right]=\\frac{1}{2}\\left[\\left\\langle x^2\\right\\rangle_n+\\left\\langle x^2\\right\\rangle_k\\right] \\\\       \\left\\langle x_1 x_2\\right\\rangle_{B, F} &amp; =\\frac{1}{\\sqrt{2}}\\left[\\langle n k| \\pm\\langle k n|\\right] x_1 x_2 \\times \\frac{1}{\\sqrt{2}}\\left[|n k\\rangle \\pm|k n\\rangle\\right] \\\\       &amp; = \\frac{1}{2}\\left[\\left\\langle n\\left|x_1\\right| n\\right\\rangle\\left\\langle k\\left|x_2\\right| k\\right\\rangle \\pm\\left\\langle n\\left|x_1\\right| k\\right\\rangle\\left\\langle k\\left|x_2\\right| n\\right\\rangle \\pm\\left\\langle k\\left|x_1\\right| n\\right\\rangle\\left\\langle n\\left|x_2\\right| k\\right\\rangle+\\left\\langle k\\left|x_1\\right| k\\right\\rangle\\left\\langle n\\left|x_2\\right| n\\right\\rangle\\right] \\\\       &amp; = \\frac{1}{2}\\left[\\langle x\\rangle_n\\langle x\\rangle_k \\pm\\langle x\\rangle_{n k}\\langle x\\rangle_{k n} \\pm\\langle x\\rangle_{k n}\\langle x\\rangle_{n k}+\\langle x\\rangle_k\\langle x\\rangle_n\\right]=\\langle x\\rangle_n\\langle x\\rangle_k \\pm\\left|\\langle x\\rangle_{n k}\\right|^2 \\end{align*}\\] <p>where</p> \\[   \\langle x\\rangle_{n k}=\\langle n|x| k\\rangle=\\int_0^L \\varphi_n^*(x) x \\varphi_k(x) d x . \\] <p>Combining this, we have</p> \\[     \\left\\langle\\left(x_1-x_2\\right)^2\\right\\rangle_{B, F}=\\left\\langle x^2\\right\\rangle_n+\\left\\langle x^2\\right\\rangle_k-2\\langle x\\rangle_n\\langle x\\rangle_k \\mp 2\\left|\\langle x\\rangle_{n k}\\right|^2 \\] <p>meaning we need only compute one extra integral.</p> <p><code>\\end{Tutorial 3 problem 4 solution}</code></p> <p>Now the hint promises that one need not compute any integrals, and this is because in the above solution, we need to change the single particle wave functions to that of the harmonic oscillator rather than the square well. But the secret sauce to this problem is recalling that the position (and momentum, and therefore Hamiltonian) can be expressed in terms of the ladder operators \\(a\\) and \\(a^\\dagger\\). Explicitly, we have</p> \\[     x = \\sqrt{\\frac{\\hbar}{2m\\omega}}\\left(a^\\dagger+a\\right) \\] <p>which means we can evaluate the required expectation values via</p> \\[\\begin{align*}         \\left\\langle x^2\\right\\rangle_n &amp; =\\left\\langle n\\left|x^2\\right| n\\right\\rangle=\\frac{\\hbar}{2 m \\omega}\\left\\langle n\\left|\\left(a^{\\dagger}+a\\right)^2\\right| n\\right\\rangle=\\frac{\\hbar}{2 m \\omega}\\left\\langle n\\left|\\left(a^{\\dagger}\\right)^2+a^{\\dagger} a+a a^{\\dagger}+a^2\\right| n\\right\\rangle \\\\         &amp; =\\frac{\\hbar}{2 m \\omega}\\left\\langle n\\left|a^{\\dagger} a+a a^{\\dagger}\\right| n\\right\\rangle=\\frac{\\hbar}{2 m \\omega}\\langle n|\\sqrt{n} \\sqrt{n}+\\sqrt{n+1} \\sqrt{n+1}| n\\rangle \\\\         &amp; =\\frac{\\hbar}{2 m \\omega}(2 n+1)=\\frac{\\hbar}{m \\omega}\\left(n+\\frac{1}{2}\\right) \\end{align*}\\] <p>Notice the appearance of the number operator and it conjugate from tutorial 2.</p> \\[\\begin{align*}         \\langle x\\rangle_n &amp; =\\langle n|x| n\\rangle=\\sqrt{\\frac{\\hbar}{2 m \\omega}}\\left\\langle n\\left|a^{\\dagger}+a\\right| n\\right\\rangle \\\\         &amp; =\\sqrt{\\frac{\\hbar}{2 m \\omega}}\\left[\\left\\langle n\\left|a^{\\dagger}\\right| n\\right\\rangle+\\langle n|a| n\\rangle\\right]=\\sqrt{\\frac{\\hbar}{2 m \\omega}}[\\langle n|\\sqrt{n+1}| n+1\\rangle+\\langle n|\\sqrt{n}| n-1\\rangle] \\\\         &amp; =\\sqrt{\\frac{\\hbar}{2 m \\omega}}[\\sqrt{n+1}\\langle n | n+1\\rangle+\\sqrt{n}\\langle n | n-1\\rangle]=0 \\text { since }\\langle n | m\\rangle=\\delta_{n m} \\end{align*}\\] <p>which is to be expected: where will be find the particle? At the bottom of the well, which is centred on \\(x=0\\). The final term to calculate are the matrix elements \\(x_nk\\), which wouldn't you know it, we calculated in tutorial 2:</p> \\[\\begin{align*}         \\langle x\\rangle_{n k} &amp; =\\langle n|x| k\\rangle=\\sqrt{\\frac{\\hbar}{2 m \\omega}}\\left\\langle n\\left|a^{\\dagger}+a\\right| k\\right\\rangle \\\\         &amp; =\\sqrt{\\frac{\\hbar}{2 m \\omega}}\\left(\\left\\langle n\\left|a^{\\dagger}\\right| k\\right\\rangle+\\langle n|a| k\\rangle\\right)=\\sqrt{\\frac{\\hbar}{2 m \\omega}}(\\langle n|\\sqrt{k+1}| k+1\\rangle+\\langle n|\\sqrt{k}| k-1\\rangle) . \\\\         &amp; =\\sqrt{\\frac{\\hbar}{2 m \\omega}}(\\sqrt{k+1}\\langle n | k+1\\rangle+\\sqrt{k}\\langle n | k-1\\rangle)=\\sqrt{\\frac{\\hbar}{2 m \\omega}}\\left(\\sqrt{n} \\delta_{n, k+1}+\\sqrt{k} \\delta_{n, k-1}\\right) \\end{align*}\\] <p>Putting everything together</p> \\[\\begin{align*}         \\left\\langle\\left(x_1-x_2\\right)^2\\right\\rangle_D &amp; =\\left\\langle x^2\\right\\rangle_n+\\left\\langle x^2\\right\\rangle_k-2\\langle x\\rangle_n\\langle x\\rangle_k=\\frac{\\hbar}{m \\omega}\\left(n+\\frac{1}{2}\\right)+\\frac{\\hbar}{m \\omega}\\left(k+\\frac{1}{2}\\right) \\\\         &amp; =\\frac{\\hbar}{m \\omega}(n+k+1) \\\\ \\end{align*}\\] <p>and</p> \\[\\begin{align*}         \\left\\langle\\left(x_1-x_2\\right)^2\\right\\rangle_{B, F}&amp;=\\left\\langle x^2\\right\\rangle_n+\\left\\langle x^2\\right\\rangle_k-2\\langle x\\rangle_n\\langle x\\rangle_k \\mp 2\\left|\\langle x\\rangle_{n k}\\right|^2 \\\\         &amp; =\\frac{\\hbar}{m \\omega}(n+k+1) \\mp \\frac{\\hbar}{m \\omega}\\left(n \\delta_{n, k+1}+k \\delta_{n, k-1}\\right) \\end{align*}\\] <p>For the lowest energy state \\((n=0, k=1)\\) the expected interparticle spacings are</p> \\[\\begin{align*}         &amp; \\sqrt{\\left\\langle\\left(x_1-x_2\\right)^2\\right\\rangle_D}=2\\frac{\\hbar}{m\\omega} \\\\         &amp; \\sqrt{\\left\\langle\\left(x_1-x_2\\right)^2\\right\\rangle_B}=2\\frac{\\hbar}{m\\omega} - \\frac{\\hbar}{m\\omega} = \\frac{\\hbar}{m\\omega}  \\\\         &amp; \\sqrt{\\left\\langle\\left(x_1-x_2\\right)^2\\right\\rangle_F}=2\\frac{\\hbar}{m\\omega} + \\frac{\\hbar}{m\\omega} = 3\\frac{\\hbar}{m\\omega} \\end{align*}\\] <p>This shows, as expected, that bosons tend to attract and fermions tend to repel as enforced by the symmetrisation postulate and associated exchange interaction.</p>"},{"location":"s-a-2/#question-2","title":"Question 2","text":"<p>Helium ground state energy</p> <ol> <li>Compute the direct integral for the ground state of helium and show the first-order correction to the energy is \\(E_{1s,1s}^{(1)} = \\frac{5}{2} \\mathrm{Ry} = 34~\\mathrm{eV}\\).</li> </ol> <p>Hint: For no reason, here is the spherical harmonic addition theorem:</p> <p> </p> <p>where \\(r_{&gt;}\\)/\\(r_{&lt;}\\) denoting the larger/smaller of the two distances \\(r_1\\) and \\(r_2\\).</p> <ol> <li>Imagine that we are back in week one, where the variational method was introduced. If we had guessed that the wave function of helium was roughly</li> </ol> <p> </p> <p>where \\(\\varphi_{nlm}(\\mathbf{r})\\) are the usual hydrogenic wave functions, explain why we would have calculated the identical result to that above, assuming that the interaction potential between electrons was the same. You can incorporate into your answer why I am nice for not having asked you to calculate the ground state energy for a trail wave function not of that form, for example, if \\(\\varphi(\\mathbf{r})=\\exp\\left(-\\alpha(r_1 - r_2)^2\\right)\\).</p>"},{"location":"s-a-2/#21","title":"2.1","text":"<p>Compute the direct integral for the ground state of helium and show the first-order correction to the energy is \\(E_{1s,1s}^{(1)} = \\frac{5}{2} \\mathrm{Ry} = 34~\\mathrm{eV}\\).</p> <p>Hint: For no reason, here is the spherical harmonic addition theorem:</p> \\[ \\frac{1}{\\left\\rvert \\mathbf{r_1} - \\mathbf{r_2} \\right\\rvert} = \\sum_{\\ell = 0}^{\\infty} \\sum_{m=-\\ell}^{\\ell} \\frac{4\\pi}{2\\ell+1} \\frac{r_{&lt;}^\\ell}{r_{&gt;}^{\\ell+1}} Y_\\ell^m {}^*    \\left(\\theta_1, \\phi_1\\right) Y_\\ell^m \\left(\\theta_2, \\phi_2\\right) \\] <p>where \\(r_{&gt;}\\)/\\(r_{&lt;}\\) denoting the larger/smaller of the two distances \\(r_1\\) and \\(r_2\\).</p> <p>The first order correction is calculated using perturbation theory, stating that</p> \\[     E_{1s,1s}^{(1)} = \\left\\langle \\psi_{1s,1s}^{SA} \\rvert H' \\rvert \\psi_{1s,1s}^{SA}\\right\\rangle \\] <p>which we saw in class defines the direct integral \\(J_{11}\\). At the time, I emphasised that such integrals had physical meanings, which was the important bit, and the actual numbers that popped out were just a computational exercise. Well, here we are.</p> <p>The direct integral of the ground state of helium is</p> \\[     E_{1s,1s}^{(1)} = \\int\\int\\psi_{100}^*\\left(\\mathbf{r}_1\\right)\\psi_{100}^*\\left(\\mathbf{r}_2\\right)\\frac{e^2}{4\\pi\\varepsilon_0 \\left\\rvert \\mathbf{r_1} - \\mathbf{r_2} \\right\\rvert}\\psi_{100}\\left(\\mathbf{r}_1\\right)\\psi_{100}\\left(\\mathbf{r}_2\\right) \\] <p>where the ground state wave function is</p> \\[     \\psi_{100}\\left(\\mathbf{r}\\right) = \\psi_{100}\\left(r,\\theta,\\phi\\right)=\\sqrt{\\frac{Z^3}{\\pi a_0^3}}e^{-Zr/a_0} \\] <p>As the hint states, to make this problem tractable, we can use the spherical harmonic addition theorem, which yields</p> \\[\\begin{align*}         E_{1 s, 1 s}^{(1)} &amp; =\\frac{Z^6 e^2}{4 \\pi^3 \\varepsilon_0 a_0^6} \\iint e^{-2 Z_1 / a_0} e^{-2 Z r_2 / a_0} \\sum_{\\ell=0}^{\\infty} \\sum_{m=-\\ell}^{\\ell} \\frac{4 \\pi}{2 \\ell+1} \\frac{r_{&lt;}^{\\ell}}{r_{&gt;}^{\\ell+1}} Y_\\ell^m{}^*\\left(\\theta_1, \\phi_1\\right) Y_\\ell^m\\left(\\theta_2, \\phi_2\\right) d^3 \\mathbf{r}_1 d^3 \\mathbf{r}_2 \\\\         &amp; =\\frac{Z^6 e^2}{4 \\pi^3 \\varepsilon_0 a_0^6} \\sum_{\\ell=0}^{\\infty} \\sum_{m=-\\ell}^{\\ell} \\frac{4 \\pi}{2 \\ell+1} \\iint e^{-2 Z\\left(r_1+r_2\\right) / a_0} \\frac{r_{&lt;}^{\\ell}}{r_{&gt;}^{\\ell+1}} Y_\\ell^m{}^*\\left(\\theta_1, \\phi_1\\right) Y_\\ell^m\\left(\\theta_2, \\phi_2\\right) d^3 \\mathbf{r}_1 d^3 \\mathbf{r}_2 \\end{align*}\\] <p>Now plugging in \\(\\ell = m = 0\\):</p> \\[\\begin{align*}         E_{1 s, 1 s}^{(1)}=\\frac{Z^6 e^2}{4 \\pi^3 \\varepsilon_0 a_0^6} &amp; (4 \\pi)^2 \\int_0^{\\infty} \\int_0^{\\infty} e^{-2 Z\\left(r_1+r_2\\right) / a_0} \\frac{1}{r_{&gt;}} r_1^2 d r_1 r_2^2 d r_1 \\\\         &amp; \\times \\int Y_{0}^{0}{}^*\\left(\\theta_1, \\phi_1\\right) Y_0^0\\left(\\theta_1, \\phi_1\\right) d \\Omega_1 \\int Y_0^0{}^*\\left(\\theta_2, \\phi_2\\right) Y_{0}^0\\left(\\theta_2, \\phi_2\\right) d \\Omega_2 \\end{align*}\\] <p>The spherical harmonics are orthonormal, so the angular integral evaluates to 1 and we are left with</p> \\[     E_{1 s, 1 s}^{(1)}=\\frac{4 Z^6 e^2}{\\pi \\varepsilon_0 a_0^6} \\int_0^{\\infty} \\int_0^{\\infty} e^{-2 Z\\left(r_1+r_2\\right) / a_0} \\frac{1}{r_{&gt;}} r_1^2 d r_1 r_2^2 d r_2 \\] <p>The trick here is to split the integral with \\(r_&gt;\\) into two parts, and with that, the rest is just cranking the handle:</p> \\[\\begin{align*}         E_{1 s, 1 s}^{(1)} &amp; =\\frac{4 Z^6 e^2}{\\pi \\varepsilon_0 a_0^6} \\int_0^{\\infty} e^{-2 Z r_1 / a_0} r_1^2 d r_1\\left[\\frac{1}{r_1} \\int_0^{r_1} e^{-2 Z {r_2} / a_0} r_2^2 d r_2+\\int_{r_1}^{\\infty} e^{-2 Z r_2 / a_0} \\frac{1}{r_2} r_2^2 d r_2\\right] \\\\         &amp; =\\frac{4 Z^6 e^2}{\\pi \\varepsilon_0 a_0^6} \\int_0^{\\infty} e^{-2 Z r_1 / a_0} r_1^2 d r_1 \\times \\bigg[ \\frac{1}{r_1}\\left(\\frac{a_0}{4 Z^3}\\right)\\left(a_0^2-e^{-2 Z_1 / a_0}\\left\\{a_0^2+2 a_0 r_1 Z+2 r_1^2 Z^2\\right\\}\\right) \\\\         &amp;\\hspace{5cm} +\\left(\\frac{a_0}{4 Z^2}\\right) e^{-2 Z_{r_1} / a_0}\\left\\{a_0+2 r_1 Z\\right\\} \\bigg] \\\\         &amp; =\\frac{Z^3 e^2}{\\pi \\varepsilon_0 a_0^5}\\bigg[         \\int_0^{\\infty}\\left(a_0^2 e^{-2 Z_1 / a_0}-e^{-4 Z_{\\mathrm{i}} / a_0}\\left\\{a_0^2+2 a_0 r_1 Z+2 r_1^2 Z^2\\right\\}\\right) r_1 d r_1 \\\\         &amp;\\hspace{2cm} + \\int_0^{\\infty} e^{-4 Z_{\\mathrm{i}} / a_0}\\left(a_0 Z+2 r_1 Z^2\\right) r_1^2 d r_1 \\bigg] \\\\         &amp; =\\frac{Z^3 e^2}{\\pi \\varepsilon_0 a_0^5}\\left[\\frac{a_0^4}{4 Z^2}-\\frac{a_0^4}{16 Z^2}-\\frac{a_0^4}{16 Z^2}-\\frac{3 a_0^4}{64 Z^2}+\\frac{a_0^4}{32 Z^2}+\\frac{3 a_0^4}{64 Z^2}\\right] \\\\         &amp; =\\frac{5 Z e^2}{32 \\pi \\varepsilon_0 a_0}=\\frac{5}{8}\\left(\\frac{Z e^2}{4 \\pi \\varepsilon_0 a_0}\\right) \\\\ \\end{align*}\\] <p>Plugging in the values for helium we get</p> \\[     E_{1 s, 1 s}^{(1)}=\\frac{5}{8} Z\\left(\\frac{e^2}{4 \\pi \\varepsilon_0 a_0}\\right)=\\frac{5}{8} 2(2 \\mathrm{Ry})=\\frac{5}{2} 13.6 \\mathrm{eV}=34~\\mathrm{eV} \\]"},{"location":"s-a-2/#22","title":"2.2","text":"<p>Imagine that we are back in week one, where the variational method was introduced. If we had guessed that the wave function of helium was roughly</p> \\[   \\psi_{He} = \\varphi_{nlm}(\\mathbf{r}_1)\\varphi_{nlm}(\\mathbf{r}_2) \\] <p>where \\(\\varphi_{nlm}(\\mathbf{r})\\) are the usual hydrogenic wave functions, explain why we would have calculated the identical result to that above, assuming that the interaction potential between electrons was the same. You can incorporate into your answer why I am nice for not having asked you to calculate the ground state energy for a trail wave function \\emph{not} of that form, for example, if \\(\\varphi(\\mathbf{r})=\\exp\\left(-\\alpha(r_1 - r_2)^2\\right)\\).</p> <p>In order to calculate the ground state energy using the variational method, we need to compute the expectation value</p> \\[     E \\le \\left\\langle \\psi | H | \\psi \\right\\rangle \\] <p>It is usual to split this into kinetic, potential and interaction terms, where</p> \\[     H = T + V + V_{int} = ((T_1 + V_1) + (T_2 + V_2)) + V_{int}. \\] <p>As we compute these expectation values, we have \\(\\varphi_{nlm}(\\mathbf{r}_{1,2})\\) as eigenstates of \\(T_1 + V_1\\) and \\(T_2 + V_2\\) respectively, meaning that each of their contributions to the expectation value would be</p> \\[   -Z^2\\,\\mathrm{Ry} \\] <p>or \\(-108.8~\\mathrm{eV}\\) in total. The final component of the expectation value would be calculate as</p> \\[   \\left\\langle \\psi | V_{int} | \\psi \\right\\rangle \\] <p>which is the direct integral that was computed above.</p> <p>The reason that I am nice is because this is only true because \\(\\varphi_{nlm}(\\mathbf{r}_{1,2})\\) are eigenstates; had I given you something like the Gaussian listed (as I had been planning), you would have had to explicitly compute the expectation values for \\(T_{1,2} + V_{1,2}\\), meaning lots of nasty integration!</p>"},{"location":"s-a-2/#question-3","title":"Question 3","text":"<p>Density of states</p> <p>In class, it was stated that the density of states \\(g(E)\\) can be calculated as the Fourier transform of the emitted field, and for an exponentially decaying excited state, the density of states is</p> \\[ g(E) = \\frac{\\hbar A_{21}/2\\pi}{\\left(E-\\hbar\\omega_{12}\\right)^2 + \\left( \\frac{\\hbar A_{21}}{2}\\right)^2} \\] <p>We are going to show exactly this.</p> <ol> <li>Explain why that given a population which decays exponentially with time dependence \\(e^{-t/\\tau}\\), the field decays with the a time dependence \\(e^{-t/2\\tau}\\).</li> <li>Calculate the Fourier transform of the emitted field,            and hence find the frequency spectrum of the radiated power in spontaneous emission(1).</li> <li>Convert this frequency spectrum to an energy spectrum, and normalise it (to 1) and voil\u00c3\u00a0, you should arrive at the density of states above (2).</li> </ol> <ol> <li>Hint: The power spectral density is computed as the square of the absolute value of the Fourier transform.</li> <li>Hint: You will need to make the (very valid) approximation that the linewidth \\(A_{21}\\) is much less than the resonance frequency \\(\\omega_{21}\\)</li> </ol>"},{"location":"s-a-2/#31","title":"3.1","text":"<p>Explain why that given a population which decays exponentially with time dependence \\(e^{-t/\\tau}\\), the field decays with the a time dependence \\(e^{-t/2\\tau}\\).</p> <p>The radiated power exhibits the same time dependence, but the power is calculated as the field squared, hence the factor of two.</p>"},{"location":"s-a-2/#32","title":"3.2","text":"<p>Calculate the Fourier transform of the emitted field,</p> \\[     E(t) = \\begin{cases}             0 &amp; t &lt; 0 \\\\             E_0 e^{-t/2\\tau} e^{-i\\omega_{21}t} &amp; t\\geq 0            \\end{cases} \\] <p>and hence find the frequency spectrum of the radiated power in spontaneous emission(1).</p> <ol> <li>Hint: The power spectral density is computed as the square of the absolute value of the Fourier transform.</li> </ol> <p>The Fourier transform of \\(E(t)\\) is</p> \\[\\begin{align*}     \\mathscr{F}\\{E(t); t\\rightarrow \\omega\\} &amp;\\equiv\\hat{E}(\\omega) = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{\\infty} E(t) e^{-i \\omega t} dt \\\\     &amp; = \\frac{1}{\\sqrt{2\\pi}}\\int_{0}^{\\infty} E_0 e^{-t/2\\tau} e^{i\\omega_{21}t} e^{-i \\omega t} dt \\\\     &amp; = \\frac{E_0}{\\sqrt{2\\pi}}\\int_{0}^{\\infty} e^{-i(\\omega - \\omega_{21})t - t/2\\tau} dt \\\\     &amp; = \\frac{E_0}{\\sqrt{2\\pi}} \\left. \\frac{e^{-i(\\omega - \\omega_{21})t - t/2\\tau}}{-i(\\omega - \\omega_{21}) - 1/2\\tau} \\right\\rvert_0^\\infty \\\\     &amp; = \\frac{E_0}{\\sqrt{2\\pi}} \\frac{1}{i(\\omega - \\omega_{21}) + 1/2\\tau} \\end{align*}\\] <p>The power is then</p> \\[\\begin{align*}     P(\\omega) &amp; = \\left\\rvert\\hat{E}(\\omega)\\right\\rvert^2 \\propto \\left\\rvert \\frac{1}{i(\\omega - \\omega_{21}) + 1/2\\tau} \\right\\rvert^2 \\\\     &amp; \\propto \\frac{1}{(\\omega - \\omega_{21})^2 + (1/2\\tau)^2} \\\\     &amp; = \\frac{1}{(\\omega - \\omega_{21})^2 + (A_{21}/2)^2} \\end{align*}\\] <p>where we have used the definition of the Einstein \\(A\\) coefficient as \\(1/\\tau\\), and have binned the factor out the front as we are going to normalise the spectrum in the next part.</p>"},{"location":"s-a-2/#33","title":"3.3","text":"<p>Convert this frequency spectrum to an energy spectrum, and normalise it (to 1) and voil\u00c3\u00a0, you should arrive at the density of states above (1).</p> <ol> <li>Hint: You will need to make the (very valid) approximation that the linewidth \\(A_{21}\\) is much less than the resonance frequency \\(\\omega_{21}\\)</li> </ol> <p>Converting to an energy spectrum, we have</p> \\[ g(E) \\propto \\frac{1}{(E - \\hbar\\omega_{21})^2 + (\\hbar A_{21}/2)^2} \\] <p>which we need to normalise. Doing so:</p> \\[ \\int_0^\\infty g(E) dE = \\int_0^\\infty \\frac{C}{(E - \\hbar\\omega_{21})^2 + (A_{21}/2)^2} dE = 1 \\] <p>Making the substitution \\(x = E-\\hbar\\omega_{21}\\)</p> \\[\\begin{align*}   1 &amp; = \\int_{-\\hbar\\omega_{21}}^\\infty \\frac{C}{x^2 + (A_{21}/2)^2} dx \\\\   &amp; = C\\left.\\frac{\\tan^{-1}(2x/\\hbar A_21)}{\\hbar A_{21}/2}\\right\\rvert_{-\\hbar\\omega_{21}}^{\\infty} \\\\   &amp; = \\frac{2C}{\\hbar A_{21}}\\left(\\frac{\\pi}{2}-\\tan^{-1}\\left(-\\frac{\\omega_{21}}{A_{21}}\\right)\\right) \\end{align*}\\] <p>Now making the assumption that \\(A_{21}\\ll\\omega_{21}\\) gives</p> \\[     1=\\frac{2\\pi C}{\\hbar A_{21}} \\Rightarrow C = \\frac{\\hbar A_{21}}{2\\pi} \\] <p>and ultimately the desired result</p> \\[     g(E) = \\frac{\\hbar A_{21}/2\\pi}{\\left(E-\\hbar\\omega_{12}\\right)^2 + \\left( \\frac{\\hbar A_{21}}{2}\\right)^2} \\]"},{"location":"s-a-2/#question-4","title":"Question 4","text":"<p>Absorption of light</p> <p>Light of frequency \\(\\omega\\) propagates in the \\(z\\) direction and is incident on an ensemble of two-level atoms. In the steady state, we can model the absorption process by assuming that the intensity falls off as \\(I(z)=I_0e^{-\\alpha z}\\).</p> <ol> <li>Show that \\(\\alpha = k\\,\\mathrm{Im}\\left[\\chi\\right]\\) where k is the wavenumber</li> <li>Show that in the case of homogeneous broadening, the absorption per unit length is given by  </li> <li>Assuming resonant conditions, by introducing the on-resonance saturation parameter, \\(s_0=\\frac{2\\Omega^2}{\\Gamma^2}\\), derive the \\emph{Beer-Lambert law}:  where \\(\\frac{I}{I_{sat}}=s_0\\).</li> <li>In the high-intensity limit (\\(s\\rightarrow\\infty\\)), this reduces to  Comment on the significance of this, in particular, what happens to the transmission as a function of light as a function of incident intensity?</li> </ol>"},{"location":"s-a-2/#41","title":"4.1","text":"<p>Show that \\(\\alpha = k\\,\\mathrm{Im}\\left[\\chi\\right]\\) where k is the wavenumber</p> <p>The electric field of the light field in the ensemble (with refractive index \\(n\\)) is given by</p> \\[\\begin{equation*}     \\mathbf{E}(z,t)=\\mathbf{E}_0e^{i\\left(k n_R z-\\omega t\\right)}e^{-k n_I z}. \\end{equation*}\\] <p>We know that the intensity is related to the electric field through</p> \\[\\begin{align*}     I(z,t)&amp;=\\frac{1}{2}\\epsilon_0 c |\\mathbf{E}(z,t)|^2 \\\\     &amp;= \\frac{\\epsilon_0 c}{2}|\\mathbf{E}_0|^2 e^{-2k n_I z} \\end{align*}\\] <p>when we plug in the electric field above. Comparing this to the form \\(I(z)=I_0e^{-\\alpha z}\\) is clear that</p> \\[\\begin{align*}     \\alpha&amp;=2k n_I \\\\     &amp;=k\\,\\mathrm{Im}\\left[\\chi\\right] \\end{align*}\\] <p>since \\(n=\\sqrt{1+\\chi}\\approx1+\\frac{\\chi}{2}\\) for small \\(\\chi\\).</p>"},{"location":"s-a-2/#42","title":"4.2","text":"<p>Show that in the case of homogeneous broadening, the absorption per unit length is given by  </p> <p>The light absorbed by a slab of atoms with thickness \\(dz\\) is</p> \\[\\begin{equation*}     dI=-\\alpha dz I \\end{equation*}\\] <p>which implies that</p> \\[\\begin{equation*}     \\frac{dI}{dz}=-k\\,\\mathrm{Im}\\left[\\chi\\right]I. \\end{equation*}\\] <p>We showed in class that the susceptibility is related to the slowly varying coherence \\(\\sigma_{12}\\) via</p> \\[\\begin{equation*}     \\chi=\\frac{2nd_{12}^2}{\\epsilon_0 \\hbar \\Omega}\\sigma_{12}. \\end{equation*}\\] <p>We also saw that in the steady state, the slowly varying coherence \\(\\sigma_{12}\\) evaluated for \\(t\\rightarrow\\infty\\) is given by</p> \\[\\begin{equation*}     \\sigma_{12}\\bigg\\rvert_{t\\rightarrow\\infty}=\\frac{i\\Omega}{2\\gamma_{\\perp}} \\frac{1-\\frac{i\\Delta}{\\gamma_{\\perp}}}{1+\\left(\\frac{\\Delta}{\\gamma_{\\perp}}\\right)^2+\\frac{\\Omega^2}{\\gamma_{\\perp}\\Gamma}} \\end{equation*}\\] <p>which in a medium with homogeneous broadening (\\(\\gamma_{\\perp}=\\frac{\\Gamma}{2}\\)) reduces to</p> \\[\\begin{equation*}     \\sigma_{12}\\bigg\\rvert_{t\\rightarrow\\infty}=\\frac{i\\Omega}{\\Gamma}\\frac{1-i\\frac{2\\Delta}{\\Gamma}}{1+\\left(\\frac{2\\Delta}{\\Gamma}\\right)^2+2\\left(\\frac{\\Omega}{\\Gamma}\\right)^2}. \\end{equation*}\\] <p>With this, it is simply a matter of plugging and playing:</p> \\[\\begin{align*}     \\frac{dI}{dz}&amp;=-\\frac{k I 2n d_{12}^2}{\\epsilon_0\\hbar\\Gamma} \\frac{1}{1+\\left(\\frac{2\\Delta}{\\Gamma}\\right)^2+2\\left(\\frac{\\Omega}{\\Gamma}\\right)^2}\\\\     &amp;=-\\frac{k I nd_{12}^2}{\\epsilon_0\\hbar}\\frac{\\Gamma}{2} \\frac{1}{\\Delta^2+\\frac{\\Gamma^2}{4}+\\frac{\\Omega^2}{2}} \\end{align*}\\] <p>where we pulled out a factor of \\(\\frac{4}{\\Gamma^2}\\) from the denominator of \\(\\mathrm{Im}\\left[\\sigma_{12}\\bigg\\rvert_{t\\rightarrow\\infty}\\right]\\) to achieve the desired form.</p>"},{"location":"s-a-2/#43","title":"4.3","text":"<p>Assuming resonant conditions, by introducing the on-resonance saturation parameter, \\(s_0=\\frac{2\\Omega^2}{\\Gamma^2}\\), derive the Beer-Lambert law:  where \\(\\frac{I}{I_{sat}}=s_0\\).</p> <p>As we are now talking about an resonant system, we are dealing with a detuning of zero (\\(\\Delta=0\\)). Next, as the on-resonance saturation parameter is given by \\(s_0=\\frac{2\\Omega^2}{\\Gamma^2}\\), it is wise to write everything in terms of \\(\\frac{2\\Omega^2}{\\Gamma^2}\\):</p> \\[\\begin{equation*}     \\frac{dI}{dz}=-\\frac{k I nd_{12}^2}{\\epsilon_0\\hbar} \\frac{\\Gamma}{2} \\frac{2}{\\Omega^2} \\frac{\\frac{2\\Omega^2}{\\Gamma^2}}{1+\\frac{2\\Omega^2}{\\Gamma^2}}. \\end{equation*}\\] <p>Now</p> \\[\\begin{equation*}     I d_{12}^2 = \\frac{1}{2}\\epsilon_0 c\\frac{|\\mathbf{E}_0|^2 d_{12}^2}{\\left(\\hbar\\Omega\\right)^2} \\end{equation*}\\] <p>which implies</p> \\[\\begin{equation*}     \\frac{dI}{dz}=-k c n \\hbar \\frac{\\Gamma}{2} \\frac{s_0}{1+s_0} \\end{equation*}\\] <p>and as \\(k=\\frac{\\omega}{c}\\), we have</p> \\[\\begin{equation*}     \\frac{dI}{dz}=-n \\hbar \\omega \\hbar \\frac{\\Gamma}{2} \\frac{s_0}{1+s_0}. \\end{equation*}\\] <p>Substituting \\(s_0=\\frac{I}{I_{sat}}\\), we arrive at the Beer-Lambert law:</p> \\[\\begin{equation*}     \\frac{1}{I}\\frac{dI}{dz}=-\\frac{n\\hbar\\omega}{I_{sat}}\\frac{\\Gamma}{2}. \\end{equation*}\\]"},{"location":"s-a-2/#44","title":"4.4","text":"<p>In the high-intensity limit (\\(s\\rightarrow\\infty\\)), this reduces to  Comment on the significance of this, in particular, what happens to the transmission as a function of light as a function of incident intensity?</p> <p>The Beer-Lambert law as derived above returns the behavior that we expect, \\(I(z)=I_0e^{-\\alpha z}\\), but only for small intensities. Explicitly, we identify that the intensity decays exponentially as light propagates through the medium and is absorbed by the two-level system.</p> <p>In the high-intensity limit we have  which has the solution \\(I(z)=I_0 - n\\hbar\\omega\\frac{\\Gamma}{2}z\\). We now identify that there is a linear absorption in the medium. But why?</p> <p>As we discussed in class, transitions experience saturation. The physical origin of saturation is intuitive: a system can only scatter so many photons per unit time. So once the system is in a regime whereby the medium cannot scatter any more light, we observe an increase in transmission. This simple principle has some extremely practical applications, including a spectroscopic technique used to stabalise laser systems to atomic transitions with an incredible degree of accuracy, so-called saturated absorption spectroscopy. Understanding of saturation and related spectroscopy was rewarded with the Nobel Prize in physics in 1981.</p>"},{"location":"s-a-2/#question-5","title":"Question 5","text":"<p>The density matrix and OBEs</p> <p>Here we are going to compute some density matrices, and then we are going to solve the optical Bloch equations.</p> <ol> <li>What is the density matrix for the state \\(\\psi = 0.577\\ket{+} + 0.577(1+i)\\ket{-}\\) in the \\(\\ket{\\pm}\\) basis?</li> <li>What is the expectation value for \\(S_y\\)?</li> <li>What is a mixed state which would give the same probabilities of measuring the system in states \\(\\ket{+}\\) and \\(\\ket{-}\\)</li> <li>Explain why we care about the difference between pure and mixed states, and what differences one might observe in experiments when using either a pure or mixed state</li> </ol> <p><code>\\begin{Computational content}</code></p> <p>The computation of density matrices can be tedious, especially once we have larger systems. Consider the state</p> \\[    \\ket{\\psi} = \\frac{1}{\\sqrt{10}}\\left( 3\\ket{++} + 1\\ket{+-} + 4 \\ket{-+} + 2\\ket{--} \\right) \\] <p>in the basis \\(|J_1\\,J_2\\,m_{J_1}\\, m_{J_2}\\rangle\\), where \\(J_1, J_2 = 1/2\\) and have been dropped from the state labels.</p> <p>Using <code>Python</code> (or equivalent) 5. Compute the density matrix \\(\\rho\\) for the above state \\(\\ket{\\psi}\\) 6. Compute the expectation value \\(\\langle \\mathbf{F}^2 \\rangle\\) for this state</p> <p>We now turn to the optical Bloch equations. We have seen that in the rotating wave approximation, we can solve them analytically, but such approximations are not always valid, and more generally, in large systems the analytical solutions become nightmarish (e.g. see appendix D of my Ph.D thesis. Consequently, we seek to solve them numerically.</p> <p>Using <code>Python</code> 7. Compute and plot the evolution of the matrix elements \\(\\rho_{11}, \\rho_{12}, \\rho_{21},\\) and \\(\\rho_{22}\\) as a function of time for realistic experimental parameters(1). 8. Use the computational package <code>[QuTiP](https://qutip.readthedocs.io/en/master/index.html)</code> to produce plots of the same matrix elements(2).</p> <p>As computational experience, competence, and confidence will vary across the class, I have provided a jupyter notebook to provide a few hot tips.</p> <ol> <li>Hint: This means that you will need to figure out what realistic parameters are.</li> <li>Hint: This is an exercise to demonstrate that using established libraries can make complex tasks simple, and thus should not require any complex computation \\emph{per se}</li> </ol>"},{"location":"s-a-2/#51","title":"5.1","text":"<p>What is the density matrix for the state \\(\\psi = 0.577\\ket{+} + 0.577(1+i)\\ket{-}\\) in the \\(\\ket{\\pm}\\) basis?</p>"},{"location":"s-a-2/#52","title":"5.2","text":"<p>What is the expectation value for \\(S_y\\)?</p>"},{"location":"s-a-2/#53","title":"5.3","text":"<p>What is a mixed state which would give the same probabilities of measuring the system in states \\(\\ket{+}\\) and \\(\\ket{-}\\)</p>"},{"location":"s-a-2/#54","title":"5.4","text":"<p>Explain why we care about the difference between pure and mixed states, and what differences one might observe in experiments when using either a pure or mixed state</p>"},{"location":"s-a-2/#55","title":"5.5","text":"<p>Compute the density matrix \\(\\rho\\) for the above state \\(\\ket{\\psi}\\)</p>"},{"location":"s-a-2/#56","title":"5.6","text":"<p>Compute the expectation value \\(\\langle \\mathbf{F}^2 \\rangle\\) for this state</p>"},{"location":"s-a-2/#57","title":"5.7","text":"<p>Compute and plot the evolution of the matrix elements \\(\\rho_{11}, \\rho_{12}, \\rho_{21},\\) and \\(\\rho_{22}\\) as a function of time for realistic experimental parameters(1).</p> <ol> <li>Hint: This means that you will need to figure out what realistic parameters are.</li> </ol>"},{"location":"s-a-2/#58","title":"5.8","text":"<p>Use the computational package <code>[QuTiP](https://qutip.readthedocs.io/en/master/index.html)</code> to produce plots of the same matrix elements(1).</p> <ol> <li>Hint: This is an exercise to demonstrate that using established libraries can make complex tasks simple, and thus should not require any complex computation per se</li> </ol> <pre><code>\n</code></pre> <p> </p> A schematic of the Stern-Gerlach experiment"},{"location":"s-t-1/","title":"Tutorial 1","text":"<pre>\n\nfrom matplotlib import pyplot\nimport numpy as np\n\nfrom common import draw_classic_axes, configure_plotting\n\nconfigure_plotting()\n\n  </pre>"},{"location":"s-t-1/#tutorial-1","title":"Tutorial 1","text":"<p>Eventually, this content will be fleshed out on the site. In the short term, you can find a .pdf of the tutorial problems and solutions below</p> <p> Tutorial 1 problems and solutions     </p>"}]}